{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A bot, short for \"robot,\" is a computer program that automates tasks or interacts with users in a predefined manner. Bots are often used to perform repetitive tasks, provide customer support, and engage in conversation with humans.\\n\\nBots can be categorized into different types based on their functionality:\\n\\n1. **Task-oriented bots**: These bots automate specific tasks, such as:\\n\\t* Sending notifications\\n\\t* Processing transactions\\n\\t* Filling out forms\\n2. **Conversational bots**: These bots simulate human-like conversations with users, often through:\\n\\t* Chatbots (e.g., chat windows or voice assistants like Siri or Alexa)\\n\\t* Messaging platforms (e.g., Facebook Messenger or WhatsApp)\\n3. **Agent bots**: These bots act as virtual customer service representatives, providing assistance and answers to user inquiries.\\n4. **Data-driven bots**: These bots analyze data and make decisions based on that information.\\n\\nBots can be created using various programming languages and frameworks, such as:\\n\\n1. Natural Language Processing (NLP) libraries like Dialogflow or Wit.ai\\n2. Messaging platform APIs like Facebook Messenger or Slack\\n3. Automation tools like Zapier or Automator\\n\\nSome popular types of bots include:\\n\\n1. **Virtual assistants**: Like Amazon\\'s Alexa, Apple\\'s Siri, or Google Assistant.\\n2. **Customer service bots**: Used by companies to provide 24/7 support to customers.\\n3. **Marketing bots**: Used for targeted advertising, lead generation, and promotional campaigns.\\n4. **Chatbots**: Common in e-commerce websites, helping users navigate through products and services.\\n\\nOverall, bots have the potential to revolutionize how we interact with technology and improve our daily lives!', response_metadata={'token_usage': {'completion_tokens': 344, 'prompt_tokens': 14, 'total_tokens': 358}, 'model_name': 'llama3', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-c7495d28-a29e-4b11-8e65-f31bc582e51f-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified following https://www.youtube.com/watch?v=02cdCd43Ccc \n",
    "API_KEY = \"NA\" #Causes ChatOpenAI to look for local models. base-url is needed to use ollama\n",
    "Model = 'llama3'\n",
    "gpt_llm = ChatOpenAI(api_key = API_KEY,model= Model, base_url=\"http://localhost:11434/v1\")\n",
    "gpt_llm.invoke('what is a bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "gpt_chain = gpt_llm|parser\n",
    "gpt_chain.invoke('what is a shark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('data.txt',encoding = 'utf-8')\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter = RecursiveCharacterTextSplitter(chunk_size = 200,chunk_overlap = 50)\n",
    "chunks = spliter.split_documents(document)\n",
    "chunks[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_storage = FAISS.from_documents(chunks,OpenAIEmbeddings())\n",
    "# retriever = vector_storage.as_retriever()\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(base_url = 'http://localhost:11434', model=\"llama3\")\n",
    "# May need: \n",
    "# !pip install faiss-cpu\n",
    "# or \n",
    "# !pip install faiss-gpu\n",
    "\n",
    "vector_storage = FAISS.from_documents(chunks, ollama_emb)\n",
    "retriever = vector_storage.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke('what is the main characteristic of the satellite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\"\"\"\n",
    "You are AI-powered chatbot designed to provide \n",
    "information and assistance for customers\n",
    "based on the context provided to you only. \n",
    "            \n",
    "Context:{context}\n",
    "Question:{question}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt.format(\n",
    "    context = ' Here is a context to use',\n",
    "    question = ' This is a question to answer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = RunnableParallel(context = retriever,question = RunnablePassthrough())\n",
    "chain = result |prompt | gpt_llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke('What is the recommended material for satelites? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke('are there any precedents to wood satellites? Do they work?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.2/docs/integrations/document_loaders/url/\n",
    "# !pip install unstructured\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "loaderhmlt = UnstructuredURLLoader(urls = [\"https://www.nature.com/articles/d41586-024-01456-z\"])\n",
    "data = loaderhmlt.load()\n",
    "spliterhtml = RecursiveCharacterTextSplitter(chunk_size = 200,chunk_overlap = 50)\n",
    "chunkhtml = spliterhtml.split_documents(data)\n",
    "chunkhtml[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The article of interest is inclluded in the first 44 chunks \n",
    "vector_storagehtml = FAISS.from_documents(chunkhtml[:44], ollama_emb)\n",
    "retrieverhtml = vector_storagehtml.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulthtml = RunnableParallel(context = retrieverhtml,question = RunnablePassthrough())\n",
    "chainhtml = resulthtml |prompt | gpt_llm | parser\n",
    "chain_htmlr = chainhtml.invoke('are there any precedents to wood satellites? Do they work?')\n",
    "chain_htmlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_htmlr2 = chainhtml.invoke('What is the recommended material for satelites? ')\n",
    "chain_htmlr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_htmlr2 = chainhtml.invoke('What is the recommended material for satelites? ')\n",
    "chain_htmlr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_htmlr2 = re.sub(r'\\. ',r'.\\n', chain_htmlr2)\n",
    "print(chain_htmlr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_htmlr3 = chainhtml.invoke('What is the main idea of the context provided? ')\n",
    "chain_htmlr3\n",
    "chain_htmlr3 = re.sub(r'\\. ',r'.\\n', chain_htmlr3)\n",
    "print(chain_htmlr3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
