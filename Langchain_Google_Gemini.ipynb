{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# import google.generativeai as genai\n",
    "sys.path.append(os.path.abspath(os.path.join('.', 'secret')))\n",
    "from secret_info import google_genai_api\n",
    "\n",
    "GOGGLE_API_KEY = google_genai_api\n",
    "# genai.configure(api_key = GOGGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A car uses an engine to convert gasoline into motion, which is then transferred through a transmission to the wheels, allowing the vehicle to move.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7, safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "chat.invoke(\"explain how a car works in one sentence\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large language models (LLMs) are AI systems trained on massive text datasets that allow for advanced natural language processing tasks such as text generation, translation, question answering, and dialogue.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as above\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)\n",
    "llm.invoke(\"explain large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "# Generate simulated data\n",
      "x_train = np.random.rand(100, 10)\n",
      "y_train = np.random.randint(2, size=(100, 1))\n",
      "\n",
      "# Define the neural network model\n",
      "model = tf.keras.models.Sequential([\n",
      "  tf.keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n",
      "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
      "])\n",
      "\n",
      "# Compile the model\n",
      "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(x_train, y_train, epochs=10)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(x_train, y_train)\n",
      "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
    "]\n",
    "response = chat.invoke(input=messages)\n",
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROMPTS\n",
    "\n",
    "### Single Prompt Interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A car is a wheeled vehicle that is used for transportation. It is typically powered by an engine, and has four wheels. Cars can be used to transport people or goods, and can be either privately owned or rented.\\n\\nCars have been around for over a century, and have undergone significant changes over the years. Early cars were powered by steam engines, and were very slow and unreliable. However, as technology improved, cars became more powerful and reliable. In the early 20th century, the internal combustion engine was invented, which made cars much more efficient and powerful.\\n\\nToday, cars are an essential part of modern life. They are used for a wide variety of purposes, and are available in a wide range of styles and prices. Cars have made it possible for people to travel more easily and quickly, and have helped to connect people all over the world.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single promt interaction: \n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "# First prompt\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = prompt | llm\n",
    "chain.invoke({'concept': 'car'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Prompt Interactions \n",
    "\n",
    "This portion uses LCEL as SimpleSequentialChain and LLChains are now deprecated, and generate an error. See: \n",
    "\n",
    "https://stackoverflow.com/questions/78508462/keyerror-in-simplesequentialchain/78562683#78562683\n",
    "\n",
    "https://github.com/langchain-ai/langchain/discussions/20137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'structure': \"A car is a complex machine that requires a deep understanding of various scientific and engineering disciplines to fully comprehend. At its core, a car is a mode of transportation designed to move people or goods from one place to another. It consists of several key components that work together to provide mobility, including an engine, transmission, wheels, and a chassis.\\n\\nThe engine is responsible for converting fuel into energy, which is then used to power the wheels and propel the car forward. The transmission allows the driver to change gears, which adjusts the ratio of engine speed to wheel speed, enabling the car to operate efficiently at different speeds and loads. The wheels provide traction and support the weight of the car, while the chassis serves as the structural framework that holds all the components together.\\n\\nIn addition to these core components, cars also incorporate a wide range of advanced technologies, including computer systems, sensors, and actuators. These technologies enhance the car's performance, safety, and convenience, enabling features such as adaptive cruise control, lane departure warning, and automatic emergency braking.\\n\\nOverall, a car is a sophisticated machine that represents the culmination of human ingenuity and engineering expertise. It combines mechanical, electrical, and computer systems to provide a safe, efficient, and enjoyable mode of transportation.\",\n",
       " 'review': \"Imagine a car as a really cool toy that lets you go on adventures. It's like a big puzzle made up of different pieces that all work together to make it move.\\n\\nThe most important piece is the engine. It's like the heart of the car, making it go. The engine takes special stuff called fuel and turns it into power. This power is like the energy that makes your legs move when you run.\\n\\nNext, there's the transmission. It's like a magic gearbox that helps the engine power the wheels. The wheels are like the car's feet, helping it move along the ground.\\n\\nThe chassis is like the car's skeleton. It's the strong frame that holds everything together, like your bones hold your body together.\\n\\nBut cars aren't just made of these basic parts. They also have lots of special gadgets that make them even cooler.\\n\\nThere are computers that help the car drive itself, like when it keeps you in the middle of the road or stops it if there's something in front.\\n\\nThere are also sensors that are like the car's eyes and ears. They can sense things around the car, like other cars or even people, and help the car stay safe.\\n\\nAnd there are actuators that are like the car's muscles. They help the car do things like turn the steering wheel or press the brakes.\\n\\nAll these pieces work together like a team to make your car a safe and fun way to get around. It's like a giant, amazing machine that helps you explore the world and go on all sorts of adventures!\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"structure\"],\n",
    "    template=\"Turn the concept description of {structure} and explain it to me like I'm five in 500 words\",\n",
    ")\n",
    "initial_chain = prompt | llm | StrOutputParser()\n",
    "review_chain = second_prompt | llm | StrOutputParser()\n",
    "\n",
    "chain = ({\"structure\" : initial_chain} \n",
    "         | RunnablePassthrough.assign(review=review_chain)\n",
    "        )\n",
    "result = chain.invoke({\"concept\": 'car'})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     19\u001b[0m second_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     20\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml_concept\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurn the concept description of \u001b[39m\u001b[38;5;132;01m{ml_concept}\u001b[39;00m\u001b[38;5;124m and explain it to me like I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm five in 500 words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m chain_two \u001b[38;5;241m=\u001b[39m second_prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m---> 25\u001b[0m overall_chain \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleSequentialChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_two\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Run the chain specifying only the input variable for the first chain.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m explanation \u001b[38;5;241m=\u001b[39m overall_chain\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/pydantic/main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/langchain/chains/sequential.py:158\u001b[0m, in \u001b[0;36mSimpleSequentialChain.validate_chains\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_chains\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate that chains are all single input/output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chain \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chain\u001b[38;5;241m.\u001b[39minput_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChains used in SimplePipeline should all have one input, got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chain\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chains'"
     ]
    }
   ],
   "source": [
    "# This example generates as error \n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "# First prompt\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# Define a second prompt \n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
    ")\n",
    "chain_two = second_prompt | llm\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two])\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "explanation = overall_chain.run(\"autoencoder\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DATAFRAME\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/toolkits/pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
