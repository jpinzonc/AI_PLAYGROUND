{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v19XlsqP7mI",
        "outputId": "d60b0715-5b9e-47f6-938b-f4cec095f607"
      },
      "source": [
        "# TEXT to SQL USING GOOGLE GEMINI MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://github.com/genieincodebottle/generative-ai/blob/main/genai/day-10/text_to_sql.ipynb\n",
        "\n",
        "#Code to mount Google Drive at Colab Notebook instance\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sqlite\n",
            "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from operator import itemgetter\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "from langchain_community.utilities.sql_database import SQLDatabase # Change the import to the latest in the lanchaing documentations\n",
        "######## Getting the API to access gemini\n",
        "# from google.colab import userdata\n",
        "# GOOGLE_API_KEY = userdata.get('GEMINI_KEY')\n",
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join('../..', 'secret')))\n",
        "from secret_info import google_genai_api\n",
        "GOOGLE_API_KEY = google_genai_api\n",
        "######## Set database for the model: \n",
        "db = SQLDatabase.from_uri('sqlite:///chinook.db') # /// = relative path, //// = absolute path\n",
        "print(db.dialect)\n",
        "print(db.get_usable_table_names())\n",
        "db.run(\"SELECT * FROM Artists LIMIT 10;\")\n",
        "######## Generating the model \n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Iron Maiden has the most albums, with a total of 21 albums.'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "######## Ask the question\n",
        "quest = \"What artist has more albums?\"\n",
        "######## Create and execute the query \n",
        "execute_query = QuerySQLDataBaseTool(db=db)\n",
        "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the {top_k} answer.\n",
        "Use the following format:\n",
        "Question: \"Question here\"\n",
        "\"SQL Query to run\"\n",
        "SQLResult: \"Result of the SQLQuery\"\n",
        "Answer: \"Final answer here\"\n",
        "Only use the following tables:\n",
        "{table_info}.\n",
        "Provide SQL query as simple string without any markdown.\n",
        "Question: {input}'''\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "write_query = create_sql_query_chain(llm, db, prompt)\n",
        "######## Format the answer\n",
        "answer_prompt = PromptTemplate.from_template(\n",
        "\"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
        "Question: {question}\n",
        "{query}\n",
        "SQL Result: {result}\n",
        "Answer: \"\"\"\n",
        ")\n",
        "answer = answer_prompt | llm | StrOutputParser()\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(query=write_query).assign(\n",
        "        result=itemgetter(\"query\") | execute_query\n",
        "    )\n",
        "    | answer\n",
        ")\n",
        "chain.invoke({\"question\": quest})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "____\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dNa79_nt5dZ"
      },
      "source": [
        "##**Install Langchain and Google Gemini related libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r76L6X4AQJEB",
        "outputId": "54bb3b04-197e-438d-8bad-94c9cea23ba8"
      },
      "outputs": [],
      "source": [
        "# None of these installed as there is an error\n",
        "!pip install -q -U langchain==0.1.2\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U langchain-google-genai==1.0.3\n",
        "%pip install --upgrade --quiet  langchain langchain-community langchain-experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkmAUJVzuG2T"
      },
      "source": [
        "# Get Gemini API Key from Secrets\n",
        "Set GEMINI_KEY secret key at Google Colab and get that here to runn Google Gemini LLM. You can get Google Gemini Key from following link https://makersuite.google.com/app/apikey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXFDa9vmuCb4"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "# GOOGLE_API_KEY = userdata.get('GEMINI_KEY')\n",
        "\n",
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join('../..', 'secret')))\n",
        "from secret_info import google_genai_api\n",
        "GOOGLE_API_KEY = google_genai_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO1eAKgEm8OM"
      },
      "source": [
        "# Loading the Data base \n",
        "Copy chinhook.db to your Google Drive\n",
        "\n",
        "Now, chinhook.db is in our directory and we can interface with it using the SQLAlchemy-driven SQLDatabase class.\n",
        "\n",
        "Location of chinhook.db\n",
        "\n",
        "/content/drive/MyDrive/Colab Notebooks/chinook.db\n",
        "\n",
        "- *I used the same file I had for the app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "V6Lo1RFGi-ut",
        "outputId": "b414cea4-1166-441c-dff0-aa219f54dc7b"
      },
      "outputs": [],
      "source": [
        "db = SQLDatabase.from_uri('sqlite:///chinook.db') # /// = relative path, //// = absolute path\n",
        "print(db.dialect)\n",
        "print(db.get_usable_table_names())\n",
        "db.run(\"SELECT * FROM Artists LIMIT 10;\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FAUURh9nWIP"
      },
      "source": [
        "# Chain\n",
        "Let’s create a simple chain that takes a question, turns it into a SQL query, executes the query, and uses the result to answer the original question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrxSgy7MnelA"
      },
      "source": [
        "# Convert question to SQL query\n",
        "The first step in a SQL chain or agent is to take the user input and convert it to a SQL query. LangChain comes with a built-in chain for this: create_sql_query_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yzgu-IBjVjJ",
        "outputId": "07eb3aa9-2757-4609-e814-4928114f2718"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "quest = \"What artist has more albums?\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=True, temperature=0.0)\n",
        "chain = create_sql_query_chain(llm, db)\n",
        "response = chain.invoke({\"question\":quest})\n",
        "\n",
        "# Generate regex pattern to remove prefix and suffix\n",
        "regex_pattern = r'^```sql\\n|\\n```$'\n",
        "\n",
        "# Remove prefix and suffix using regex to get proper SQL query\n",
        "modified_response = re.sub(regex_pattern, '', response)\n",
        "print(\"This is the query: \\n\", modified_response)\n",
        "db.run(modified_response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhKxXMd-nlct"
      },
      "source": [
        "# Execute SQL query\n",
        "Now that we’ve generated a SQL query, we’ll want to execute it.\n",
        "\n",
        "We can use the QuerySQLDatabaseTool to easily add query execution to our chain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "r9_JsnIMj1o8",
        "outputId": "d0c94f3e-1523-49fa-97e2-12c304e8345e"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "execute_query = QuerySQLDataBaseTool(db=db)\n",
        "\n",
        "template = '''Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the {top_k} answer.\n",
        "Use the following format:\n",
        "\n",
        "Question: \"Question here\"\n",
        "\"SQL Query to run\"\n",
        "SQLResult: \"Result of the SQLQuery\"\n",
        "Answer: \"Final answer here\"\n",
        "\n",
        "Only use the following tables:\n",
        "\n",
        "{table_info}.\n",
        "\n",
        "Provide SQL query as simple string without any markdown.\n",
        "\n",
        "Question: {input}'''\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "write_query = create_sql_query_chain(llm, db, prompt)\n",
        "chain = write_query | execute_query\n",
        "chain.invoke({\"question\": quest})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbItDxiEnxg2"
      },
      "source": [
        "# Answer the question\n",
        "Now that we’ve got a way to automatically generate and execute queries, we just need to combine the original question and SQL query result to generate a final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "6MpiJVumkngx",
        "outputId": "ecc23fa9-9a7d-4180-af64-6de0f6e164e8"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "quest = \"What artist has more albums?\"\n",
        "\n",
        "answer_prompt = PromptTemplate.from_template(\n",
        "\"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
        "\n",
        "Question: {question}\n",
        "{query}\n",
        "SQL Result: {result}\n",
        "Answer: \"\"\"\n",
        ")\n",
        "\n",
        "answer = answer_prompt | llm | StrOutputParser()\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(query=write_query).assign(\n",
        "        result=itemgetter(\"query\") | execute_query\n",
        "    )\n",
        "    | answer\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": quest})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9bV_Z0bn5Kv"
      },
      "source": [
        "# Agents\n",
        "LangChain has an SQL Agent which provides a more flexible way of interacting with SQL databases. The main advantages of using the SQL Agent are:\n",
        "\n",
        "It can answer questions based on the databases’ schema as well as on the databases’ content (like describing a specific table).\n",
        "It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
        "It can answer questions that require multiple dependent queries.\n",
        "It will save tokens by only considering the schema from relevant tables.\n",
        "To initialize the agent, we use create_sql_agent function. This agent contains the SQLDatabaseToolkit which contains tools to:\n",
        "\n",
        "- Create and execute queries\n",
        "- Check query syntax\n",
        "- Retrieve table descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JBXPleWnn7XM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'What artist has more albums?', 'output': 'Iron Maiden'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.agent_toolkits import create_sql_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "\n",
        "agent_executor = create_sql_agent(llm,\n",
        "                                  toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
        "                                  agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "                                  verbose=False)\n",
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": quest\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
