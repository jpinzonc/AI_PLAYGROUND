{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# import google.generativeai as genai\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'secret')))\n",
    "from secret_info import google_genai_api\n",
    "\n",
    "GOGGLE_API_KEY = google_genai_api\n",
    "# genai.configure(api_key = GOGGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A car's engine converts the chemical energy in gasoline into mechanical energy, which is transmitted through a transmission to the wheels, causing them to rotate and propel the car forward.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7, safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "chat.invoke(\"explain how a car works in one sentence\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Importance of Corals to Ocean Life:**\\n\\n* **Habitat and Shelter:** Corals provide a complex and intricate habitat for a vast array of marine organisms, including fish, invertebrates, and algae. They offer shelter, protection from predators, and feeding grounds.\\n* **Biodiversity Hotspot:** Coral reefs are known as the \"rainforests of the sea\" due to their incredible biodiversity. They support over 25% of all marine species, including many threatened and endangered ones.\\n* **Food Source:** Corals and the organisms they support provide a vital food source for various marine animals, including fish, turtles, and seabirds.\\n* **Oxygen Production:** Corals, through photosynthesis, contribute significantly to oxygen production in the oceans. They play a crucial role in maintaining a healthy marine ecosystem.\\n* **Water Filtration:** Corals help filter and purify seawater, removing pollutants and sediment. They improve water quality and clarity, supporting the growth of other marine organisms.\\n* **Climate Regulation:** Coral reefs absorb carbon dioxide from the atmosphere, mitigating climate change and ocean acidification.\\n\\n**Importance of Corals to Society:**\\n\\n* **Economic Value:** Coral reefs support major industries, such as tourism, fishing, and diving. Their aesthetic beauty and biodiversity attract tourists, generating significant revenue for coastal communities.\\n* **Protection from Storms:** Coral reefs act as natural breakwaters, reducing the impact of waves and storm surges on coastal areas. They protect shorelines from erosion and flooding.\\n* **Medical Discoveries:** Coral reefs are a source of novel compounds with potential medical applications, including antibiotics, anti-cancer agents, and pain relievers.\\n* **Educational and Research:** Corals provide valuable research opportunities for scientists studying marine ecology, climate change, and conservation. They serve as natural laboratories for understanding the complex interactions within ocean ecosystems.\\n* **Cultural and Spiritual Significance:** Coral reefs hold cultural and spiritual importance for many coastal communities. They are often associated with traditional beliefs, ceremonies, and folklore.\\n\\n**Threats to Coral Reefs:**\\n\\n* Climate change (ocean warming and acidification)\\n* Pollution (plastic waste, sewage, agricultural runoff)\\n* Overfishing\\n* Coastal development\\n* Destructive fishing practices'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as above\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)\n",
    "llm.invoke(\"Why are corals important to ocean life and our society\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAT MODEL\n",
    "\n",
    "#### Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fibonacci(n):\n",
      "    \"\"\"Calculates the nth fibonacci number.\n",
      "\n",
      "    Args:\n",
      "        n: The index of the fibonacci number to calculate.\n",
      "\n",
      "    Returns:\n",
      "        The nth fibonacci number.\n",
      "    \"\"\"\n",
      "\n",
      "    if n < 2:\n",
      "        return n\n",
      "    else:\n",
      "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    n = int(input(\"Enter the index of the fibonacci number to calculate: \"))\n",
      "    print(f\"The {n}th fibonacci number is {fibonacci(n)}\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script to calculate the fibonacci sequence \")\n",
    "]\n",
    "response = chat.invoke(input=messages)\n",
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROMPTS\n",
    "\n",
    "### Single Prompt Interaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Training in deep learning involves fine-tuning the model's parameters to optimize its performance on a given dataset. It is an iterative process where the model learns from the data and adjusts its internal structure to improve its accuracy.\\n\\nDuring training, the model is presented with a set of labeled data, where the input data is paired with the corresponding output or target. The model then propagates the input data through its layers, generating an output prediction. This prediction is compared to the true label, and the difference, known as the loss, is calculated.\\n\\nThe model's parameters are then updated using a backpropagation algorithm, which calculates the gradients of the loss function with respect to the parameters. These gradients provide information about how the parameters affect the loss, allowing the model to adjust them in a way that minimizes the loss.\\n\\nThe training process continues through multiple epochs, where each epoch involves passing the entire dataset through the model once. As the model trains, it gradually learns the patterns and relationships in the data, improving its ability to make accurate predictions on unseen data.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single promt interaction: \n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "# First prompt\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = prompt | llm\n",
    "chain.invoke({'concept': 'training'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Prompt Interactions \n",
    "\n",
    "This portion uses LCEL as SimpleSequentialChain and LLChains are now deprecated, and generate an error. See: \n",
    "\n",
    "https://stackoverflow.com/questions/78508462/keyerror-in-simplesequentialchain/78562683#78562683\n",
    "\n",
    "https://github.com/langchain-ai/langchain/discussions/20137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'structure': 'A neural network is a type of machine learning algorithm inspired by the human brain. It consists of interconnected layers of nodes, called neurons, which process data and transmit it to the next layer. Each neuron takes in a weighted sum of its inputs and applies an activation function to produce an output.\\n\\nNeural networks are trained on large datasets using a process called backpropagation. During training, the network learns to adjust its weights and biases to minimize the error between its predictions and the true labels. Once trained, neural networks can be used for tasks such as image recognition, natural language processing, and speech recognition.',\n",
       " 'review': \"Imagine your brain as a giant playground filled with tiny workers called neurons. These neurons are like little computers that can do simple math and talk to each other.\\n\\nNow, let's say you want to teach your brain to recognize cats. You show it a bunch of pictures of cats and non-cats, and it tries to figure out which ones are cats.\\n\\nTo do this, the neurons form layers like a stack of blocks. The first layer looks at the basic features of the picture, like shapes and colors. The next layer combines these features to find more complex patterns, like ears and whiskers. The final layer decides if the picture is a cat or not.\\n\\nEach neuron has a special number that tells it how important its input is. If the input is very important, the number is big. If it's not so important, the number is small.\\n\\nWhen a neuron gets a bunch of inputs, it adds them up, like when you add up your toys to see how many you have. Then, it uses a special rule, called an activation function, to decide if it should pass the information on to the next layer.\\n\\nIf the neuron thinks the information is important enough, it sends it to the next layer. If not, it doesn't.\\n\\nNow, here's the clever part. When your brain makes a mistake, it doesn't just give up. It goes back and changes the numbers on the neurons to make them better at recognizing cats. It does this over and over until it gets really good at it.\\n\\nThat's how neural networks learn! They're like super smart brains that can learn from data and make predictions. They're used for all sorts of things, like helping computers understand language, recognize objects in pictures, and even play games.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"structure\"],\n",
    "    template=\"Turn the concept description of {structure} and explain it to me like I'm five in 500 words\",\n",
    ")\n",
    "initial_chain = prompt | llm | StrOutputParser()\n",
    "review_chain = second_prompt | llm | StrOutputParser()\n",
    "\n",
    "chain = ({\"structure\" : initial_chain} \n",
    "         | RunnablePassthrough.assign(review=review_chain)\n",
    "        )\n",
    "result = chain.invoke({\"concept\": 'neural network'})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     19\u001b[0m second_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m     20\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml_concept\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurn the concept description of \u001b[39m\u001b[38;5;132;01m{ml_concept}\u001b[39;00m\u001b[38;5;124m and explain it to me like I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm five in 500 words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m chain_two \u001b[38;5;241m=\u001b[39m second_prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m---> 25\u001b[0m overall_chain \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleSequentialChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_two\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Run the chain specifying only the input variable for the first chain.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m explanation \u001b[38;5;241m=\u001b[39m overall_chain\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/pydantic/v1/main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/morgage/lib/python3.12/site-packages/langchain/chains/sequential.py:158\u001b[0m, in \u001b[0;36mSimpleSequentialChain.validate_chains\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_chains\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate that chains are all single input/output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chain \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chain\u001b[38;5;241m.\u001b[39minput_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChains used in SimplePipeline should all have one input, got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chain\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chains'"
     ]
    }
   ],
   "source": [
    "# This example generates as error \n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY)\n",
    "# First prompt\n",
    "template = \"\"\"\n",
    "You are an expert data scientist with an expertise in building deep learning models. \n",
    "Explain the concept of {concept} in 200 words\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"concept\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = prompt | llm\n",
    "\n",
    "# Define a second prompt \n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_concept\"],\n",
    "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
    ")\n",
    "chain_two = second_prompt | llm\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two])\n",
    "# Run the chain specifying only the input variable for the first chain.\n",
    "explanation = overall_chain.run(\"autoencoder\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DATAFRAME\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/toolkits/pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOGGLE_API_KEY, convert_system_message_to_human=False, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
