{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video: \n",
    "\n",
    "https://www.youtube.com/watch?v=9ccl1_Wu24Q\n",
    "\n",
    "Document: \n",
    "\n",
    "https://alejandro-ao.com/chat-with-mysql-using-python-and-langchain/\n",
    "\n",
    " - This is another example: \n",
    "\n",
    "    https://python.langchain.com/docs/use_cases/sql/quickstart/\n",
    "\n",
    "Install LANGCHAIN\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/get_started/introduction\n",
    "\n",
    "%pip install langchain mysql-connector-python \n",
    "\n",
    "%pip install langchain-openai\n",
    "\n",
    "For OPEN AI, you need an APIKEY: https://platform.openai.com/\n",
    "\n",
    "https://pypi.org/project/langchain-openai/\n",
    "\n",
    "\n",
    "FREE SQLITE DATABASES https://www.sqlitetutorial.net/sqlite-sample-database/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "database = 'data/chinook.db'\n",
    "from secret.secret_info import openai_key\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "con = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL CHAIN\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# The template is an string that ask for the question in this case: \n",
    "# schema is the schema from the database \n",
    "# question: the question that you want to answer\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "                {schema}\n",
    "\n",
    "                Question: {question}\n",
    "                SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_uri = 'sqlite:///./data/chinook.db' \n",
    "db = SQLDatabase.from_uri(sqlite_uri)\n",
    "\n",
    "def get_schema(_):\n",
    "    # schema = db.get_table_info()\n",
    "    return db.get_table_info()\n",
    "\n",
    "my_schema = get_schema(db)\n",
    "print(my_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prompt.format(schema = my_schema,  question = \" How many users are there? \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create llm \n",
    "llm = ChatOpenAI(api_key = openai_key)\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = 'how many albums are there in the database?'\n",
    "sql_chain.invoke({\"question\": user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = 'how many albums are there in the database?'\n",
    "full_chain.invoke({\"question\": user_question})\n",
    "\n",
    "# 'There are 347 albums in the database.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STILL MORE IN THE VIDEO\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Anthropic - NOT A FREE PLAN\n",
    "\n",
    "Documentation\n",
    "\n",
    "https://python.langchain.com/docs/integrations/chat/anthropic/\n",
    "\n",
    "anthropic api key: \n",
    "\n",
    "https://console.anthropic.com/settings/keys\n",
    "\n",
    "\n",
    "Install: \n",
    "\n",
    "%pip install -qU langchain-anthropic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret.secret_info import anthropic_key\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatAnthropic(temperature=0, api_key=anthropic_key, model_name=\"claude-3-opus-20240229\")\n",
    "\n",
    "system = (\n",
    "    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    ")\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Korean\",\n",
    "        \"text\": \"I love Python\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____ \n",
    "\n",
    "# OCTO AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret.secret_info import octo\n",
    "\n",
    "from langchain_community.chat_models import ChatOctoAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOctoAI(max_tokens=300, octoai_api_token = octo, model_name=\"mixtral-8x7b-instruct\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Tell me about Leonardo da Vinci briefly.\"),\n",
    "]\n",
    "print(chat(messages).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
