{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML PARSER USING OLLAMA \n",
    "\n",
    "- https://github.com/InsightEdge01/ScrapegraphAIOllamallama3/blob/main/app.py\n",
    "\n",
    "\n",
    "- https://www.youtube.com/watch?v=2BTI3KIiGHU\n",
    "\n",
    "\n",
    "- https://scrapegraph-doc.onrender.com/docs/Graphs/smart_scraper_graph\n",
    "\n",
    "!pip install scrapegraphai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapegraphai.graphs import SmartScraperGraph\n",
    "import nest_asyncio  # Import nest_asyncio module for asynchronous operations\n",
    "nest_asyncio.apply()  # Apply nest_asyncio to resolve any issues with asyncio event loop\n",
    "\n",
    "# Configuration dictionary for the graph\n",
    "graph_config = {\n",
    "    \"llm\": {\n",
    "        \"model\": \"ollama/llama3\",  # Specify the model for the llm\n",
    "        \"temperature\": 0,  # Set temperature parameter for llm\n",
    "        \"format\": \"json\",  # Specify the output format as JSON for Ollama\n",
    "        \"base_url\": \"http://localhost:11434\",  # Set the base URL for Ollama\n",
    "    },\n",
    "    \"embeddings\": {\n",
    "        \"model\": \"ollama/nomic-embed-text\",  # Specify the model for embeddings\n",
    "        \"base_url\": \"http://localhost:11434\",  # Set the base URL for Ollama\n",
    "    },\n",
    "    \"verbose\": True,  # Enable verbose mode for debugging purposes\n",
    "}\n",
    "\n",
    "# Initialize SmartScraperGraph with prompt, source, and configuration\n",
    "smart_scraper_graph = SmartScraperGraph(\n",
    "    #prompt=\"List all the content\",  # Set prompt for scraping\n",
    "    prompt=\"DESCRIBE THE PAGE\",\n",
    "    # Source URL or HTML content to scrape\n",
    "    #source=\"https://github.com/InsightEdge01\",\n",
    "    source=\"https://jpinzon.pyscriptapps.com/loan-calculator/latest/\",  #\"https://perinim.github.io/projects\",\n",
    "    config=graph_config  # Pass the graph configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Executing Fetch Node ---\n",
      "--- (Fetching HTML from: https://jpinzon.pyscriptapps.com/loan-calculator/latest/) ---\n",
      "--- Executing Parse Node ---\n",
      "--- Executing RAG Node ---\n",
      "--- (updated chunks metadata) ---\n",
      "--- (tokens compressed and vector stored) ---\n",
      "--- Executing GenerateAnswer Node ---\n",
      "Processing chunks: 100%|██████████| 1/1 [01:03<00:00, 63.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'page_description': 'A loan calculator page with a menu to calculate loan amortization. The page allows users to enter information such as interest rate, loan amount, and monthly payment. It also displays results including the number of payments, years, months, total paid (principal and interest), and an amortization schedule.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST CASE - SIMPLE PAGE\n",
    "prompt1=\"DESCRIBE THE PAGE\"\n",
    "source1=\"https://jpinzon.pyscriptapps.com/loan-calculator/latest/\"\n",
    "\n",
    "smart_scraper_graph = SmartScraperGraph(prompt=prompt1, source=source1, config=graph_config)\n",
    "\n",
    "result = smart_scraper_graph.run()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Executing Fetch Node ---\n",
      "--- (Fetching HTML from: https://en.wikipedia.org/wiki/Copa_Am%C3%A9rica) ---\n",
      "--- Executing Parse Node ---\n",
      "--- Executing RAG Node ---\n",
      "--- (updated chunks metadata) ---\n",
      "--- (tokens compressed and vector stored) ---\n",
      "--- Executing GenerateAnswer Node ---\n",
      "Processing chunks: 100%|██████████| 2/2 [00:00<00:00, 2937.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Chile'}\n"
     ]
    }
   ],
   "source": [
    "# SECOND CASE - MORE DATA IN THE URL \n",
    "# This one one takes about 6 mins. It maybe cause the wikipedia page contains a lot of information \n",
    "prompt2=\"what country has hosted the Copa America More times?\"\n",
    "source2=\"https://en.wikipedia.org/wiki/Copa_Am%C3%A9rica\"\n",
    "\n",
    "smart_scraper_graph = SmartScraperGraph(prompt=prompt2, source=source2, config=graph_config)\n",
    "\n",
    "result = smart_scraper_graph.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_llm_parser(prompt, source, config):\n",
    "    smart_scraper_graph = SmartScraperGraph(prompt=prompt, source=source, config=config)\n",
    "    result = smart_scraper_graph.run()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_config = {\n",
    "    \"llm\": {\n",
    "        \"model\": \"ollama/llama3\",  # Specify the model for the llm\n",
    "        \"temperature\": 0,  # Set temperature parameter for llm\n",
    "        \"format\": \"json\",  # Specify the output format as JSON for Ollama\n",
    "        \"base_url\": \"http://localhost:11434\",  # Set the base URL for Ollama\n",
    "    },\n",
    "    \"embeddings\": {\n",
    "        \"model\": \"ollama/nomic-embed-text\",  # Specify the model for embeddings\n",
    "        \"base_url\": \"http://localhost:11434\",  # Set the base URL for Ollama\n",
    "    },\n",
    "    \"verbose\": False,  # Enable verbose mode for debugging purposes\n",
    "    \"headless\" : True\n",
    "}\n",
    "\n",
    "url = \"https://www.arlingtontx.gov/city_hall/departments/garbage_recycling/household_hazardous_waste/environmental_collection_center\"\n",
    "q = \"What is the name, address and schedule of the recycling location in the page provided?\",\n",
    "rec_center = html_llm_parser(q, url, graph_config)\n",
    "rec_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
