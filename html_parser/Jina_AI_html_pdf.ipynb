{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=od6AaKhKYmg\n",
    "\n",
    "https://colab.research.google.com/drive/1gwYTL6q6XScxec0460xga8q789LXYaW7?usp=sharing\n",
    "\n",
    "https://jina.ai/reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def beautifulsoup_web_scrape_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html class=\"\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0, user-scalable=no\" name=\"viewport\"/>\n",
      "<meta content=\"We’re on a journey to advance and democratize artificial intelligence through open source and open science.\" name=\"description\"/>\n",
      "<meta content=\"1321688464574422\" property=\"fb:app_id\"/>\n",
      "<meta content=\"summary_large_image\" name=\"twitter:card\"/>\n",
      "<meta content=\"@huggingface\" name=\"twitter:site\"/>\n",
      "<meta content=\"Training and Finetuning Embedding Models with Sentence Transformers v3\" property=\"og:title\"/>\n",
      "<meta content=\"website\" property=\"og:type\"/>\n",
      "<meta content=\"https://huggingface.co/blog/train-sentence-transformers\" property=\"og:url\"/>\n",
      "<meta content=\"https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png\" property=\"og:image\"/>\n",
      "<link href=\"/front/build/kube-0932549/style.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"https://fonts.gstatic.com\" rel=\"preconnect\"/>\n",
      "<link href=\"https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap\" rel=\"stylesheet\"/>\n",
      "<link href=\"https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap\" rel=\"stylesheet\"/>\n",
      "<link as=\"style\" href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" onload=\"this.onload=null;this.rel='stylesheet'\" rel=\"preload\"/>\n",
      "<noscript>\n",
      "<link href=\"https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css\" rel=\"stylesheet\"/>\n",
      "</noscript>\n",
      "<link href=\"https://huggingface.co/blog/train-sentence-transformers\" rel=\"canonical\"/>\n",
      "<link href=\"https://huggingface.co/blog/zh/train-sentence-transformers\" hreflang=\"zh\" rel=\"alternate\"/> <!-- HEAD_svelte-vwinwk_START --><link href=\"/blog/feed.xml\" rel=\"alternate\" title=\"Hugging Face Blog\" type=\"application/rss+xml\"/><!-- HEAD_svelte-vwinwk_END -->\n",
      "<title>Training and Finetuning Embedding Models with Sentence Transformers v3</title>\n",
      "<script data-domain=\"huggingface.co\" defer=\"\" event-loggedin=\"false\" src=\"/js/script.pageview-props.js\"></script>\n",
      "<script>\n",
      "\t\t\twindow.plausible =\n",
      "\t\t\t\twindow.plausible ||\n",
      "\t\t\t\tfunction () {\n",
      "\t\t\t\t\t(window.plausible.q = window.plausible.q || []).push(arguments);\n",
      "\t\t\t\t};\n",
      "\t\t</script>\n",
      "<script>\n",
      "\t\t\twindow.hubConfig = JSON.parse(`{\"features\":{\"signupDisabled\":false},\"sshGitUrl\":\"git@hf.co\",\"moonHttpUrl\":\"https://huggingface.co\",\"captchaApiKey\":\"bd5f2066-93dc-4bdd-a64b-a24646ca3859\",\"captchaDisabledOnSignup\":true,\"datasetViewerPublicUrl\":\"https://datasets-server.huggingface.co\",\"stripePublicKey\":\"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc\",\"environment\":\"production\",\"userAgent\":\"HuggingFace (production)\",\"spacesIframeDomain\":\"hf.space\",\"spacesApiUrl\":\"https://api.hf.space\",\"docSearchKey\":\"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6\",\"logoDev\":{\"apiUrl\":\"https://img.logo.dev/\",\"apiKey\":\"pk_UHS2HZOeRnaSOdDp7jbd5w\"}}`);\n",
      "\t\t</script>\n",
      "<script defer=\"\" src=\"https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js\" type=\"text/javascript\"></script>\n",
      "</head>\n",
      "<body class=\"flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black BlogPage\">\n",
      "<div class=\"flex min-h-screen flex-col\">\n",
      "<div class=\"SVELTE_HYDRATER contents\" data-props='{\"classNames\":\"\",\"isWide\":false,\"isZh\":false}' data-target=\"MainHeader\"><header class=\"border-b border-gray-100\"><div class=\"w-full px-4 container flex h-16 items-center\"><div class=\"flex flex-1 items-center\"><a class=\"mr-5 flex flex-none items-center lg:mr-6\" href=\"/\"><img alt=\"Hugging Face's logo\" class=\"w-7 md:mr-2\" src=\"/front/assets/huggingface_logo-noborder.svg\"/>\n",
      "<span class=\"hidden whitespace-nowrap text-lg font-bold md:block\">Hugging Face</span></a>\n",
      "<div class=\"relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6\"><input autocomplete=\"off\" class=\"w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl\" name=\"\" placeholder=\"Search models, datasets, users...\" spellcheck=\"false\" type=\"text\" value=\"\"/>\n",
      "<svg aria-hidden=\"true\" class=\"absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg>\n",
      "</div>\n",
      "<div class=\"flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden\"><button class=\"relative z-40 flex h-6 w-8 items-center justify-center\" type=\"button\"><svg aria-hidden=\"true\" class=\"text-xl\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 10 10\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\" fill-rule=\"evenodd\"></path></svg>\n",
      "</button>\n",
      "</div></div>\n",
      "<nav aria-label=\"Main\" class=\"ml-auto hidden lg:block\"><ul class=\"flex items-center space-x-1.5 xl:space-x-2\"><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700\" href=\"/models\"><svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-indigo-500\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" style=\"\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" fill=\"currentColor\" opacity=\".25\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" fill=\"currentColor\" opacity=\".5\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg>\n",
      "\t\t\t\t\tModels</a>\n",
      "</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700\" href=\"/datasets\"><svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-red-500\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" style=\"\" viewbox=\"0 0 25 25\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><ellipse cx=\"12.5\" cy=\"5\" fill=\"currentColor\" fill-opacity=\"0.25\" rx=\"7.5\" ry=\"2\"></ellipse><path d=\"M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z\" fill=\"currentColor\"></path></svg>\n",
      "\t\t\t\t\tDatasets</a>\n",
      "</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700\" href=\"/spaces\"><svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-blue-500\" focusable=\"false\" height=\"1em\" role=\"img\" viewbox=\"0 0 25 25\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z\" fill=\"currentColor\" opacity=\".5\"></path><path clip-rule=\"evenodd\" d=\"M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z\" fill=\"currentColor\" fill-rule=\"evenodd\" opacity=\".75\"></path><path d=\"M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z\" fill=\"currentColor\" opacity=\".25\"></path></svg>\n",
      "\t\t\t\t\tSpaces</a>\n",
      "</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/posts\"><svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500 !text-yellow-500\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 12 12\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path clip-rule=\"evenodd\" d=\"M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg>\n",
      "\t\t\t\t\tPosts</a>\n",
      "</li><li><a class=\"group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700\" href=\"/docs\"><svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-yellow-500\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z\" fill=\"currentColor\" opacity=\"0.5\"></path><path d=\"M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z\" fill=\"currentColor\" fill-opacity=\"0.75\"></path><path clip-rule=\"evenodd\" d=\"M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path><path d=\"M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z\" fill=\"currentColor\" opacity=\"0.5\"></path></svg>\n",
      "\t\t\t\t\tDocs</a>\n",
      "</li>\n",
      "<li class=\"max-2xl:hidden\"><div class=\"relative\">\n",
      "<button class=\"px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center\" type=\"button\">\n",
      "<svg aria-hidden=\"true\" class=\"mr-1.5 text-gray-400 group-hover:text-green-500\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path class=\"uim-tertiary\" d=\"M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z\" fill=\"currentColor\" opacity=\".5\"></path><path class=\"uim-primary\" d=\"M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z\" fill=\"currentColor\"></path></svg>\n",
      "\t\t\tSolutions\n",
      "\t\t</button>\n",
      "</div></li>\n",
      "<li><a class=\"group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/pricing\">Pricing\n",
      "\t\t\t</a></li>\n",
      "<li><div class=\"relative group\">\n",
      "<button class=\"px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center\" type=\"button\">\n",
      "<svg aria-hidden=\"true\" class=\"text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 18\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path clip-rule=\"evenodd\" d=\"M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path><path clip-rule=\"evenodd\" d=\"M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path><path clip-rule=\"evenodd\" d=\"M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path><path clip-rule=\"evenodd\" d=\"M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg>\n",
      "</button>\n",
      "</div></li>\n",
      "<li><hr class=\"h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800\"/></li>\n",
      "<li><a class=\"block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400\" href=\"/login\">Log In\n",
      "\t\t\t\t</a></li>\n",
      "<li><a class=\"rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black\" href=\"/join\">Sign Up\n",
      "\t\t\t\t\t</a></li></ul></nav></div></header></div>\n",
      "<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"SSOBanner\"></div>\n",
      "<main class=\"flex flex-1 flex-col\"><div class=\"container relative flex flex-row justify-center gap-4\"><div class=\"max-w-3xl pb-16 pt-6 max-lg:overflow-hidden lg:flex-1 lg:pt-16 2xl:max-w-4xl\"><div class=\"blog-content copiable-code-container prose mx-auto lg:prose-lg 2xl:prose-lg prose-h1:mb-3 lg:px-8 [&amp;_h1]:!mr-0\"><div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"RepoCodeCopy\"><div></div></div>\n",
      "<div class=\"mb-4\"><a class=\"flex items-center font-sans !text-gray-500 !no-underline hover:!underline\" href=\"/blog\"><svg aria-hidden=\"true\" class=\"mr-2 h-3 w-3\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M14 26l1.41-1.41L7.83 17H28v-2H7.83l7.58-7.59L14 6L4 16l10 10z\" fill=\"currentColor\"></path></svg>\n",
      "\t\t\t\t\t\tBack to Articles</a></div>\n",
      "<h1 class=\"group relative flex items-center\"><!-- HTML_TAG_START -->\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#training-and-finetuning-embedding-models-with-sentence-transformers-v3\" id=\"training-and-finetuning-embedding-models-with-sentence-transformers-v3\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTraining and Finetuning Embedding Models with Sentence Transformers v3\n",
      "\t</span>\n",
      "<!-- HTML_TAG_END --></h1>\n",
      "<div><div class=\"mb-6 flex items-center gap-x-4 text-base\">\n",
      "<span class=\"text-sm sm:text-base\">Published\n",
      "\t\t\t\tMay 28, 2024</span></div>\n",
      "<a class=\"btn mb-5 font-sans text-sm no-underline\" href=\"https://github.com/huggingface/blog/blob/main/train-sentence-transformers.md\" target=\"_blank\">Update on GitHub</a></div>\n",
      "<div class=\"not-prose mb-6 lg:hidden\"><div class=\"SVELTE_HYDRATER contents\" data-props='{\"maxShown\":6,\"apiUrlPrefix\":\"/api/blog/train-sentence-transformers\",\"postLoginRedirectUrl\":\"train-sentence-transformers\",\"size\":\"sm\",\"style\":\"horizontal\",\"color\":\"gray\",\"upvotedColor\":\"orange\",\"upvoted\":false,\"upvoters\":[{\"_id\":\"5dfb0c8bda6d0311fd3d5434\",\"avatarUrl\":\"/avatars/67cf91ea59ad44c7080f1d99537e974d.svg\",\"isPro\":false,\"fullname\":\"Takatsugu Nokubi\",\"user\":\"knok\",\"type\":\"user\"},{\"_id\":\"5e0eed1ffcf41d740b699666\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e0eed1ffcf41d740b699666/jJnkTB9wsP4QBcIRZqZFD.jpeg\",\"isPro\":false,\"fullname\":\"Blanc Swan\",\"user\":\"blancsw\",\"type\":\"user\"},{\"_id\":\"5e56829137cb5b49818287ea\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e56829137cb5b49818287ea/8HYzJeRc4b9Wu7BfJwibS.png\",\"isPro\":false,\"fullname\":\"Lee Junbum\",\"user\":\"beomi\",\"type\":\"user\"},{\"_id\":\"5e9b38f84957053f60648a2d\",\"avatarUrl\":\"/avatars/dc487fced46eacee93f96b6c966c8912.svg\",\"isPro\":false,\"fullname\":\"vijay G\",\"user\":\"vijayg\",\"type\":\"user\"},{\"_id\":\"5ea4f7a7ba91ce67ad45a95e\",\"avatarUrl\":\"/avatars/93703e565323afcd226a76cf6baeb0f7.svg\",\"isPro\":false,\"fullname\":\"Nick Doiron\",\"user\":\"monsoon-nlp\",\"type\":\"user\"},{\"_id\":\"5f353bb37e58354338621655\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg\",\"isPro\":true,\"fullname\":\"Nicholas Broad\",\"user\":\"nbroad\",\"type\":\"user\"},{\"_id\":\"5f4066e079c1ba4c353d0c75\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png\",\"isPro\":false,\"fullname\":\"Snehal\",\"user\":\"spate141\",\"type\":\"user\"},{\"_id\":\"5f43d8ac79c1ba4c353d0df2\",\"avatarUrl\":\"/avatars/2b23d9444bd39d39d4c912d520bac4c8.svg\",\"isPro\":false,\"fullname\":\"AJ\",\"user\":\"Buckeyes2019\",\"type\":\"user\"},{\"_id\":\"5ff5d596f244529b3ec0fb89\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png\",\"isPro\":false,\"fullname\":\"Philipp Schmid\",\"user\":\"philschmid\",\"type\":\"user\"},{\"_id\":\"60107b385ac3e86b3ea4fc34\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg\",\"isPro\":true,\"fullname\":\"Daniel van Strien\",\"user\":\"davanstrien\",\"type\":\"user\"},{\"_id\":\"60196690dd31fde3c1062960\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1612277330660-noauth.jpeg\",\"isPro\":false,\"fullname\":\"Nandan Thakur\",\"user\":\"nthakur\",\"type\":\"user\"},{\"_id\":\"6032802e1f993496bc14d9e3\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png\",\"isPro\":false,\"fullname\":\"Omar Sanseviero\",\"user\":\"osanseviero\",\"type\":\"user\"}],\"upvotes\":131}' data-target=\"UpvoteControl\"><div class=\"flex flex-wrap items-center gap-2.5 pt-1\"><a class=\"self-start\" href=\"/login?next=train-sentence-transformers\"><div class=\"shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850\"><input class=\"peer hidden\" disabled=\"\" type=\"checkbox\"/>\n",
      "<svg aria-hidden=\"true\" class=\"text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 12 12\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z\" fill=\"currentColor\"></path></svg>\n",
      "\t\tUpvote\n",
      "\n",
      "\t\t<div class=\"font-semibold text-orange-500\">131</div></div>\n",
      "</a>\n",
      "<ul class=\"flex items-center flex-row text-base\"><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"knok\"><a href=\"/knok\" title=\"knok\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/67cf91ea59ad44c7080f1d99537e974d.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"blancsw\"><a href=\"/blancsw\" title=\"blancsw\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e0eed1ffcf41d740b699666/jJnkTB9wsP4QBcIRZqZFD.jpeg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"beomi\"><a href=\"/beomi\" title=\"beomi\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e56829137cb5b49818287ea/8HYzJeRc4b9Wu7BfJwibS.png\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"vijayg\"><a href=\"/vijayg\" title=\"vijayg\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/dc487fced46eacee93f96b6c966c8912.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"monsoon-nlp\"><a href=\"/monsoon-nlp\" title=\"monsoon-nlp\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/93703e565323afcd226a76cf6baeb0f7.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"nbroad\"><a href=\"/nbroad\" title=\"nbroad\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg\"/>\n",
      "</a>\n",
      "</li>\n",
      "<li class=\"text-gray-600 hover:text-gray-700 order-last ml-3\"><button class=\"btn -ml-3 translate-x-px rounded-full border-2 border-white bg-gradient-to-br px-1.5 py-0.5 text-xs\">+125</button></li></ul></div>\n",
      "</div></div>\n",
      "<div class=\"not-prose\"><div class=\"SVELTE_HYDRATER contents\" data-props='{\"authors\":[{\"author\":{\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png\",\"fullname\":\"Tom Aarsen\",\"name\":\"tomaarsen\",\"type\":\"user\",\"isPro\":false,\"isHf\":true,\"isMod\":false}}],\"translators\":[],\"proofreaders\":[],\"lang\":\"en\"}' data-target=\"BlogAuthorsByline\"><div class=\"not-prose\"><div class=\"mb-12 flex flex-wrap items-center gap-x-5 gap-y-3.5\">\n",
      "<span class=\"inline-block\"><span class=\"contents\"><a class=\"flex items-center leading-tight\" href=\"/tomaarsen\"><img alt=\"Tom Aarsen's avatar\" class=\"m-0 mr-2.5 size-9 !rounded-full sm:mr-3 sm:size-12\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png\"/>\n",
      "<div class=\"text-gray-900 dark:text-gray-300\"><span class=\"block font-mono text-xs !leading-tight underline\">tomaarsen</span>\n",
      "<span class=\"fullname font-sans font-semibold max-sm:text-sm\">Tom Aarsen</span>\n",
      "<div class=\"flex items-center\"></div>\n",
      "</div></a>\n",
      "</span>\n",
      "</span></div>\n",
      "</div></div></div>\n",
      "<!-- HTML_TAG_START -->\n",
      "<p>\n",
      "<div class=\"absolute -left-12 z-10 h-full not-prose hidden lg:block\"><div class=\"sticky top-4 flex\"><div class=\"pt-[0.175rem]\">\n",
      "<span class=\"peer\" tabindex=\"0\"><button class=\"select-none hover:cursor-pointer\"><svg aria-hidden=\"true\" class=\"text-lg opacity-80 hover:opacity-100\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 10 10\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path clip-rule=\"evenodd\" d=\"M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z\" fill-rule=\"evenodd\"></path></svg></button></span>\n",
      "<div class=\"invisible w-0 -translate-x-24 -translate-y-6 overflow-hidden rounded-xl border bg-white transition-transform hover:visible hover:w-52 hover:translate-x-0 peer-focus-within:visible peer-focus-within:w-52 peer-focus-within:translate-x-0\"><nav aria-label=\"Secondary\" class=\"max-h-[550px] overflow-y-auto p-3\"><ul><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#table-of-contents\" title=\"Table of Contents\"><!-- HTML_TAG_START -->Table of Contents<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#why-finetune\" title=\"Why Finetune?\"><!-- HTML_TAG_START -->Why Finetune?<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#training-components\" title=\"Training Components\"><!-- HTML_TAG_START -->Training Components<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#dataset\" title=\"Dataset\"><!-- HTML_TAG_START -->Dataset<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#data-on-hugging-face-hub\" title=\"Data on Hugging Face Hub\"><!-- HTML_TAG_START -->Data on Hugging Face Hub<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#local-data-csv-json-parquet-arrow-sql\" title=\"Local Data (CSV, JSON, Parquet, Arrow, SQL)\"><!-- HTML_TAG_START -->Local Data (CSV, JSON, Parquet, Arrow, SQL)<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#local-data-that-requires-pre-processing\" title=\"Local Data that requires pre-processing\"><!-- HTML_TAG_START -->Local Data that requires pre-processing<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#dataset-format\" title=\"Dataset Format\"><!-- HTML_TAG_START -->Dataset Format<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#loss-function\" title=\"Loss Function\"><!-- HTML_TAG_START -->Loss Function<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#training-arguments\" title=\"Training Arguments\"><!-- HTML_TAG_START -->Training Arguments<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#evaluator\" title=\"Evaluator\"><!-- HTML_TAG_START -->Evaluator<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#embeddingsimilarityevaluator-with-stsb\" title=\"EmbeddingSimilarityEvaluator with STSb\"><!-- HTML_TAG_START -->EmbeddingSimilarityEvaluator with STSb<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#tripletevaluator-with-allnli\" title=\"TripletEvaluator with AllNLI\"><!-- HTML_TAG_START -->TripletEvaluator with AllNLI<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#trainer\" title=\"Trainer\"><!-- HTML_TAG_START -->Trainer<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#callbacks\" title=\"Callbacks\"><!-- HTML_TAG_START -->Callbacks<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#multi-dataset-training\" title=\"Multi-Dataset Training\"><!-- HTML_TAG_START -->Multi-Dataset Training<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#deprecation\" title=\"Deprecation\"><!-- HTML_TAG_START -->Deprecation<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"></ul>\n",
      "</li><li class=\"mb-3 text-sm last:mb-0\"><a class=\"mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&amp;&gt;*]:break-words\" href=\"#additional-resources\" title=\"Additional Resources\"><!-- HTML_TAG_START -->Additional Resources<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-1\"><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#training-examples\" title=\"Training Examples\"><!-- HTML_TAG_START -->Training Examples<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li><li><a class=\"mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500\" href=\"#documentation\" title=\"Documentation\"><!-- HTML_TAG_START -->Documentation<!-- HTML_TAG_END --></a>\n",
      "<ul class=\"pl-2\"></ul>\n",
      "</li></ul>\n",
      "</li></ul></nav></div></div></div></div><a href=\"https://sbert.net/\">Sentence Transformers</a> is a Python library for using and training embedding models for a wide range of applications, such as retrieval augmented generation, semantic search, semantic textual similarity, paraphrase mining, and more. Its v3.0 update is the largest since the project's inception, introducing a new training approach. In this blogpost, I'll show you how to use it to finetune Sentence Transformer models to improve their performance on specific tasks. You can also use this method to train new Sentence Transformer models from scratch.</p>\n",
      "<p>Finetuning Sentence Transformers now involves several components, including datasets, loss functions, training arguments, evaluators, and the new trainer itself. I'll go through each of these components in detail and provide examples of how to use them to train effective models.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#table-of-contents\" id=\"table-of-contents\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTable of Contents\n",
      "\t</span>\n",
      "</h2>\n",
      "<ul>\n",
      "<li><a href=\"#why-finetune\">Why Finetune?</a></li>\n",
      "<li><a href=\"#training-components\">Training Components</a></li>\n",
      "<li><a href=\"#dataset\">Dataset</a><ul>\n",
      "<li><a href=\"#data-on-hugging-face-hub\">Data on Hugging Face Hub</a></li>\n",
      "<li><a href=\"#local-data-csv-json-parquet-arrow-sql\">Local Data (CSV, JSON, Parquet, Arrow, SQL)</a></li>\n",
      "<li><a href=\"#local-data-that-requires-pre-processing\">Local Data that requires pre-processing</a></li>\n",
      "<li><a href=\"#dataset-format\">Dataset Format</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><a href=\"#loss-function\">Loss Function</a></li>\n",
      "<li><a href=\"#training-arguments\">Training Arguments</a></li>\n",
      "<li><a href=\"#evaluator\">Evaluator</a><ul>\n",
      "<li><a href=\"#embeddingsimilarityevaluator-with-stsb\">EmbeddingSimilarityEvaluator with STSb</a></li>\n",
      "<li><a href=\"#tripletevaluator-with-allnli\">TripletEvaluator with AllNLI</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><a href=\"#trainer\">Trainer</a><ul>\n",
      "<li><a href=\"#callbacks\">Callbacks</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><a href=\"#multi-dataset-training\">Multi-Dataset Training</a></li>\n",
      "<li><a href=\"#deprecation\">Deprecation</a></li>\n",
      "<li><a href=\"#additional-resources\">Additional Resources</a><ul>\n",
      "<li><a href=\"#training-examples\">Training Examples</a></li>\n",
      "<li><a href=\"#documentation\">Documentation</a></li>\n",
      "</ul>\n",
      "</li>\n",
      "</ul>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#why-finetune\" id=\"why-finetune\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tWhy Finetune?\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>Finetuning Sentence Transformer models can significantly enhance their performance on specific tasks. This is because each task requires a unique notion of similarity. Let's consider a couple of news article headlines as an example:</p>\n",
      "<ul>\n",
      "<li>\"Apple launches the new iPad\"</li>\n",
      "<li>\"NVIDIA is gearing up for the next GPU generation\"</li>\n",
      "</ul>\n",
      "<p>Depending on the use case, we might want similar or dissimilar embeddings for these texts. For instance, a classification model for news articles could treat these texts as similar since they both belong to the Technology category. On the other hand, a semantic textual similarity or retrieval model should consider them dissimilar due to their distinct meanings.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#training-components\" id=\"training-components\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTraining Components\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>Training Sentence Transformer models involves the following components:</p>\n",
      "<ol>\n",
      "<li><a href=\"#dataset\"><strong>Dataset</strong></a>: The data used for training and evaluation.</li>\n",
      "<li><a href=\"#loss-function\"><strong>Loss Function</strong></a>: A function that quantifies the model's performance and guides the optimization process.</li>\n",
      "<li><a href=\"#training-arguments\"><strong>Training Arguments</strong></a> (optional): Parameters that influence training performance and tracking/debugging.</li>\n",
      "<li><a href=\"#evaluator\"><strong>Evaluator</strong></a> (optional): A tool for evaluating the model before, during, or after training.</li>\n",
      "<li><a href=\"#trainer\"><strong>Trainer</strong></a>: Brings together the model, dataset, loss function, and other components for training.</li>\n",
      "</ol>\n",
      "<p>Now, let's dive into each of these components in more detail.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#dataset\" id=\"dataset\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tDataset\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>The <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer\"><code>SentenceTransformerTrainer</code></a> uses <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset\"><code>datasets.Dataset</code></a> or <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict\"><code>datasets.DatasetDict</code></a> instances for training and evaluation. You can load data from the Hugging Face Datasets Hub or use local data in various formats such as CSV, JSON, Parquet, Arrow, or SQL.</p>\n",
      "<p>Note: Many Hugging Face datasets that work out of the box with Sentence Transformers have been tagged with <code>sentence-transformers</code>, allowing you to easily find them by browsing to <a href=\"https://huggingface.co/datasets?other=sentence-transformers\">https://huggingface.co/datasets?other=sentence-transformers</a>. We strongly recommend that you browse these datasets to find training datasets that might be useful for your tasks.</p>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#data-on-hugging-face-hub\" id=\"data-on-hugging-face-hub\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tData on Hugging Face Hub\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>To load data from datasets in the Hugging Face Hub, use the <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset\"><code>load_dataset</code></a> function:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "\n",
      "train_dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair-class\"</span>, split=<span class=\"hljs-string\">\"train\"</span>)\n",
      "eval_dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair-class\"</span>, split=<span class=\"hljs-string\">\"dev\"</span>)\n",
      "\n",
      "<span class=\"hljs-built_in\">print</span>(train_dataset)\n",
      "<span class=\"hljs-string\">\"\"\"</span>\n",
      "<span class=\"hljs-string\">Dataset({</span>\n",
      "<span class=\"hljs-string\">    features: ['premise', 'hypothesis', 'label'],</span>\n",
      "<span class=\"hljs-string\">    num_rows: 942069</span>\n",
      "<span class=\"hljs-string\">})</span>\n",
      "<span class=\"hljs-string\">\"\"\"</span>\n",
      "</code></pre>\n",
      "<p>Some datasets, like <a href=\"https://huggingface.co/datasets/sentence-transformers/all-nli\"><code>sentence-transformers/all-nli</code></a>, have multiple subsets with different data formats. You need to specify the subset name along with the dataset name.</p>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#local-data-csv-json-parquet-arrow-sql\" id=\"local-data-csv-json-parquet-arrow-sql\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tLocal Data (CSV, JSON, Parquet, Arrow, SQL)\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>If you have local data in common file formats, you can easily load it using <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset\"><code>load_dataset</code></a> too:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "\n",
      "dataset = load_dataset(<span class=\"hljs-string\">\"csv\"</span>, data_files=<span class=\"hljs-string\">\"my_file.csv\"</span>)\n",
      "<span class=\"hljs-comment\"># or</span>\n",
      "dataset = load_dataset(<span class=\"hljs-string\">\"json\"</span>, data_files=<span class=\"hljs-string\">\"my_file.json\"</span>)\n",
      "</code></pre>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#local-data-that-requires-pre-processing\" id=\"local-data-that-requires-pre-processing\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tLocal Data that requires pre-processing\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>If your local data requires pre-processing, you can use <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_dict\"><code>datasets.Dataset.from_dict</code></a> to initialize your dataset with a dictionary of lists:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> Dataset\n",
      "\n",
      "anchors = []\n",
      "positives = []\n",
      "<span class=\"hljs-comment\"># Open a file, perform preprocessing, filtering, cleaning, etc.</span>\n",
      "<span class=\"hljs-comment\"># and append to the lists</span>\n",
      "\n",
      "dataset = Dataset.from_dict({\n",
      "    <span class=\"hljs-string\">\"anchor\"</span>: anchors,\n",
      "    <span class=\"hljs-string\">\"positive\"</span>: positives,\n",
      "})\n",
      "</code></pre>\n",
      "<p>Each key in the dictionary becomes a column in the resulting dataset.</p>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#dataset-format\" id=\"dataset-format\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tDataset Format\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>It's crucial to ensure that your dataset format matches your chosen <a href=\"#loss-function\">loss function</a>. This involves checking two things:</p>\n",
      "<ol>\n",
      "<li>If your loss function requires a <em>Label</em> (as indicated in the <a href=\"https://sbert.net/docs/sentence_transformer/loss_overview.html\">Loss Overview</a> table), your dataset must have a column named <strong>\"label\"</strong> or <strong>\"score\"</strong>.</li>\n",
      "<li>All columns other than <strong>\"label\"</strong> or <strong>\"score\"</strong> are considered <em>Inputs</em> (as indicated in the <a href=\"https://sbert.net/docs/sentence_transformer/loss_overview.html\">Loss Overview</a> table). The number of these columns must match the number of valid inputs for your chosen loss function. The names of the columns don't matter, <strong>only their order matters</strong>.</li>\n",
      "</ol>\n",
      "<p>For example, if your loss function accepts <code>(anchor, positive, negative) triplets</code>, then your first, second, and third dataset columns correspond with <code>anchor</code>, <code>positive</code>, and <code>negative</code>, respectively. This means that your first and second column must contain texts that should embed closely, and that your first and third column must contain texts that should embed far apart. That is why depending on your loss function, your dataset column order matters.</p>\n",
      "<p>Consider a dataset with columns <code>[\"text1\", \"text2\", \"label\"]</code>, where the <code>\"label\"</code> column contains floating point similarity scores. This dataset can be used with <code>CoSENTLoss</code>, <code>AnglELoss</code>, and <code>CosineSimilarityLoss</code> because:</p>\n",
      "<ol>\n",
      "<li>The dataset has a \"label\" column, which is required by these loss functions.</li>\n",
      "<li>The dataset has 2 non-label columns, matching the number of inputs required by these loss functions.</li>\n",
      "</ol>\n",
      "<p>If the columns in your dataset are not ordered correctly, use <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.select_columns\"><code>Dataset.select_columns</code></a> to reorder them. Additionally, remove any extraneous columns (e.g., <code>sample_id</code>, <code>metadata</code>, <code>source</code>, <code>type</code>) using <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.remove_columns\"><code>Dataset.remove_columns</code></a>, as they will be treated as inputs otherwise.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#loss-function\" id=\"loss-function\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tLoss Function\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>Loss functions measure how well a model performs on a given batch of data and guide the optimization process. The choice of loss function depends on your available data and target task. Refer to the <a href=\"https://sbert.net/docs/sentence_transformer/loss_overview.html\">Loss Overview</a> for a comprehensive list of options.</p>\n",
      "<p>Most loss functions can be initialized with just the <code>SentenceTransformer</code> <code>model</code> that you're training:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers <span class=\"hljs-keyword\">import</span> SentenceTransformer\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.losses <span class=\"hljs-keyword\">import</span> CoSENTLoss\n",
      "\n",
      "<span class=\"hljs-comment\"># Load a model to train/finetune</span>\n",
      "model = SentenceTransformer(<span class=\"hljs-string\">\"FacebookAI/xlm-roberta-base\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># Initialize the CoSENTLoss</span>\n",
      "<span class=\"hljs-comment\"># This loss requires pairs of text and a floating point similarity score as a label</span>\n",
      "loss = CoSENTLoss(model)\n",
      "\n",
      "<span class=\"hljs-comment\"># Load an example training dataset that works with our loss function:</span>\n",
      "train_dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair-score\"</span>, split=<span class=\"hljs-string\">\"train\"</span>)\n",
      "<span class=\"hljs-string\">\"\"\"</span>\n",
      "<span class=\"hljs-string\">Dataset({</span>\n",
      "<span class=\"hljs-string\">    features: ['sentence1', 'sentence2', 'label'],</span>\n",
      "<span class=\"hljs-string\">    num_rows: 942069</span>\n",
      "<span class=\"hljs-string\">})</span>\n",
      "<span class=\"hljs-string\">\"\"\"</span>\n",
      "</code></pre>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#training-arguments\" id=\"training-arguments\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTraining Arguments\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>The <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments\"><code>SentenceTransformersTrainingArguments</code></a> class allows you to specify parameters that influence training performance and tracking/debugging. While optional, experimenting with these arguments can help improve training efficiency and provide insights into the training process.</p>\n",
      "<p>In the Sentence Transformers documentation, I've outlined some of the most useful training arguments. I would recommend reading it in <a href=\"https://sbert.net/docs/sentence_transformer/training_overview.html#training-arguments\">Training Overview &gt; Training Arguments</a>.</p>\n",
      "<p>Here's an example of how to initialize <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments\"><code>SentenceTransformersTrainingArguments</code></a>:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> sentence_transformers.training_args <span class=\"hljs-keyword\">import</span> SentenceTransformerTrainingArguments\n",
      "\n",
      "args = SentenceTransformerTrainingArguments(\n",
      "    <span class=\"hljs-comment\"># Required parameter:</span>\n",
      "    output_dir=<span class=\"hljs-string\">\"models/mpnet-base-all-nli-triplet\"</span>,\n",
      "    <span class=\"hljs-comment\"># Optional training parameters:</span>\n",
      "    num_train_epochs=<span class=\"hljs-number\">1</span>,\n",
      "    per_device_train_batch_size=<span class=\"hljs-number\">16</span>,\n",
      "    per_device_eval_batch_size=<span class=\"hljs-number\">16</span>,\n",
      "    warmup_ratio=<span class=\"hljs-number\">0.1</span>,\n",
      "    fp16=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Set to False if your GPU can't handle FP16</span>\n",
      "    bf16=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Set to True if your GPU supports BF16</span>\n",
      "    batch_sampler=BatchSamplers.NO_DUPLICATES,  <span class=\"hljs-comment\"># Losses using \"in-batch negatives\" benefit from no duplicates</span>\n",
      "    <span class=\"hljs-comment\"># Optional tracking/debugging parameters:</span>\n",
      "    eval_strategy=<span class=\"hljs-string\">\"steps\"</span>,\n",
      "    eval_steps=<span class=\"hljs-number\">100</span>,\n",
      "    save_strategy=<span class=\"hljs-string\">\"steps\"</span>,\n",
      "    save_steps=<span class=\"hljs-number\">100</span>,\n",
      "    save_total_limit=<span class=\"hljs-number\">2</span>,\n",
      "    logging_steps=<span class=\"hljs-number\">100</span>,\n",
      "    run_name=<span class=\"hljs-string\">\"mpnet-base-all-nli-triplet\"</span>,  <span class=\"hljs-comment\"># Used in W&amp;B if `wandb` is installed</span>\n",
      ")\n",
      "</code></pre>\n",
      "<p>Note that <code>eval_strategy</code> was introduced in <code>transformers</code> version <code>4.41.0</code>. Prior versions should use <code>evaluation_strategy</code> instead.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#evaluator\" id=\"evaluator\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tEvaluator\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>You can provide the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer\"><code>SentenceTransformerTrainer</code></a> with an <code>eval_dataset</code> to get the evaluation loss during training, but it may be useful to get more concrete metrics during training, too. For this, you can use evaluators to assess the model's performance with useful metrics before, during, or after training. You can both an <code>eval_dataset</code> and an evaluator, one or the other, or neither. They evaluate based on the <code>eval_strategy</code> and <code>eval_steps</code> <a href=\"#training-arguments\">Training Arguments</a>.</p>\n",
      "<p>Here are the implemented Evaluators that come with Sentence Tranformers:</p>\n",
      "<div class=\"max-w-full overflow-auto\">\n",
      "<table>\n",
      "<thead><tr>\n",
      "<th>Evaluator</th>\n",
      "<th>Required Data</th>\n",
      "</tr>\n",
      "\n",
      "<tbody><tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#binaryclassificationevaluator\"><code>BinaryClassificationEvaluator</code></a></td>\n",
      "<td>Pairs with class labels</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#embeddingsimilarityevaluator\"><code>EmbeddingSimilarityEvaluator</code></a></td>\n",
      "<td>Pairs with similarity scores</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#informationretrievalevaluator\"><code>InformationRetrievalEvaluator</code></a></td>\n",
      "<td>Queries (qid =&gt; question), Corpus (cid =&gt; document), and relevant documents (qid =&gt; set[cid])</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#mseevaluator\"><code>MSEEvaluator</code></a></td>\n",
      "<td>Source sentences to embed with a teacher model and target sentences to embed with the student model. Can be the same texts.</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#paraphraseminingevaluator\"><code>ParaphraseMiningEvaluator</code></a></td>\n",
      "<td>Mapping of IDs to sentences &amp; pairs with IDs of duplicate sentences.</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#rerankingevaluator\"><code>RerankingEvaluator</code></a></td>\n",
      "<td>List of {'query': '..', 'positive': [...], 'negative': [...]} dictionaries.</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#translationevaluator\"><code>TranslationEvaluator</code></a></td>\n",
      "<td>Pairs of sentences in two separate languages.</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#tripletevaluator\"><code>TripletEvaluator</code></a></td>\n",
      "<td>(anchor, positive, negative) pairs.</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</thead></table>\n",
      "</div>\n",
      "<p>Additionally, you can use <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#sequentialevaluator\"><code>SequentialEvaluator</code></a> to combine multiple evaluators into one, which can then be passed to the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer\"><code>SentenceTransformerTrainer</code></a>.</p>\n",
      "<p>If you don't have the necessary evaluation data but still want to track the model's performance on common benchmarks, you can use these evaluators with data from Hugging Face:</p>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#embeddingsimilarityevaluator-with-stsb\" id=\"embeddingsimilarityevaluator-with-stsb\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tEmbeddingSimilarityEvaluator with STSb\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>The STS Benchmark (a.k.a. STSb) is a commonly used benchmarking dataset to measure the model's understanding of semantic textual similarity of short texts like \"A man is feeding a mouse to a snake.\".</p>\n",
      "<p>Feel free to browse the <a href=\"https://huggingface.co/datasets/sentence-transformers/stsb\">sentence-transformers/stsb</a> dataset on Hugging Face.</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.evaluation <span class=\"hljs-keyword\">import</span> EmbeddingSimilarityEvaluator, SimilarityFunction\n",
      "\n",
      "<span class=\"hljs-comment\"># Load the STSB dataset</span>\n",
      "eval_dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/stsb\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># Initialize the evaluator</span>\n",
      "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
      "    sentences1=eval_dataset[<span class=\"hljs-string\">\"sentence1\"</span>],\n",
      "    sentences2=eval_dataset[<span class=\"hljs-string\">\"sentence2\"</span>],\n",
      "    scores=eval_dataset[<span class=\"hljs-string\">\"score\"</span>],\n",
      "    main_similarity=SimilarityFunction.COSINE,\n",
      "    name=<span class=\"hljs-string\">\"sts-dev\"</span>,\n",
      ")\n",
      "<span class=\"hljs-comment\"># Run evaluation manually:</span>\n",
      "<span class=\"hljs-comment\"># print(dev_evaluator(model))</span>\n",
      "\n",
      "<span class=\"hljs-comment\"># Later, you can provide this evaluator to the trainer to get results during training</span>\n",
      "</code></pre>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#tripletevaluator-with-allnli\" id=\"tripletevaluator-with-allnli\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTripletEvaluator with AllNLI\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>AllNLI is a concatenation of the <a href=\"https://huggingface.co/datasets/stanfordnlp/snli\">SNLI</a> and <a href=\"https://huggingface.co/datasets/nyu-mll/multi_nli\">MultiNLI</a> datasets, both of which are datasets for Natural Language Inference. This task is traditionally for determining whether two texts are an entailment, contradiction, or neither. It has since been adopted for training embedding models, as the entailing and contradictory sentences make for useful <code>(anchor, positive, negative)</code> triplets: a common format for training embedding models. </p>\n",
      "<p>In this snippet, it is used to evaluate how frequently the model considers the anchor text and the entailing text to be more similar than the anchor text and the contradictory text. An example text is \"An older man is drinking orange juice at a restaurant.\".</p>\n",
      "<p>Feel free to browse the <a href=\"https://huggingface.co/datasets/sentence-transformers/all-nli\">sentence-transformers/all-nli</a> dataset on Hugging Face.</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.evaluation <span class=\"hljs-keyword\">import</span> TripletEvaluator, SimilarityFunction\n",
      "\n",
      "<span class=\"hljs-comment\"># Load triplets from the AllNLI dataset</span>\n",
      "max_samples = <span class=\"hljs-number\">1000</span>\n",
      "eval_dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"triplet\"</span>, split=<span class=\"hljs-string\">f\"dev[:<span class=\"hljs-subst\">{max_samples}</span>]\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># Initialize the evaluator</span>\n",
      "dev_evaluator = TripletEvaluator(\n",
      "    anchors=eval_dataset[<span class=\"hljs-string\">\"anchor\"</span>],\n",
      "    positives=eval_dataset[<span class=\"hljs-string\">\"positive\"</span>],\n",
      "    negatives=eval_dataset[<span class=\"hljs-string\">\"negative\"</span>],\n",
      "    main_distance_function=SimilarityFunction.COSINE,\n",
      "    name=<span class=\"hljs-string\">f\"all-nli-<span class=\"hljs-subst\">{max_samples}</span>-dev\"</span>,\n",
      ")\n",
      "<span class=\"hljs-comment\"># Run evaluation manually:</span>\n",
      "<span class=\"hljs-comment\"># print(dev_evaluator(model))</span>\n",
      "\n",
      "<span class=\"hljs-comment\"># Later, you can provide this evaluator to the trainer to get results during training</span>\n",
      "</code></pre>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#trainer\" id=\"trainer\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTrainer\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>The <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer\"><code>SentenceTransformerTrainer</code></a> brings together the model, dataset, loss function, and other components for training:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers <span class=\"hljs-keyword\">import</span> (\n",
      "    SentenceTransformer,\n",
      "    SentenceTransformerTrainer,\n",
      "    SentenceTransformerTrainingArguments,\n",
      "    SentenceTransformerModelCardData,\n",
      ")\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.losses <span class=\"hljs-keyword\">import</span> MultipleNegativesRankingLoss\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.training_args <span class=\"hljs-keyword\">import</span> BatchSamplers\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.evaluation <span class=\"hljs-keyword\">import</span> TripletEvaluator\n",
      "\n",
      "<span class=\"hljs-comment\"># 1. Load a model to finetune with 2. (Optional) model card data</span>\n",
      "model = SentenceTransformer(\n",
      "    <span class=\"hljs-string\">\"microsoft/mpnet-base\"</span>,\n",
      "    model_card_data=SentenceTransformerModelCardData(\n",
      "        language=<span class=\"hljs-string\">\"en\"</span>,\n",
      "        license=<span class=\"hljs-string\">\"apache-2.0\"</span>,\n",
      "        model_name=<span class=\"hljs-string\">\"MPNet base trained on AllNLI triplets\"</span>,\n",
      "    )\n",
      ")\n",
      "\n",
      "<span class=\"hljs-comment\"># 3. Load a dataset to finetune on</span>\n",
      "dataset = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"triplet\"</span>)\n",
      "train_dataset = dataset[<span class=\"hljs-string\">\"train\"</span>].select(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">100_000</span>))\n",
      "eval_dataset = dataset[<span class=\"hljs-string\">\"dev\"</span>]\n",
      "test_dataset = dataset[<span class=\"hljs-string\">\"test\"</span>]\n",
      "\n",
      "<span class=\"hljs-comment\"># 4. Define a loss function</span>\n",
      "loss = MultipleNegativesRankingLoss(model)\n",
      "\n",
      "<span class=\"hljs-comment\"># 5. (Optional) Specify training arguments</span>\n",
      "args = SentenceTransformerTrainingArguments(\n",
      "    <span class=\"hljs-comment\"># Required parameter:</span>\n",
      "    output_dir=<span class=\"hljs-string\">\"models/mpnet-base-all-nli-triplet\"</span>,\n",
      "    <span class=\"hljs-comment\"># Optional training parameters:</span>\n",
      "    num_train_epochs=<span class=\"hljs-number\">1</span>,\n",
      "    per_device_train_batch_size=<span class=\"hljs-number\">16</span>,\n",
      "    per_device_eval_batch_size=<span class=\"hljs-number\">16</span>,\n",
      "    warmup_ratio=<span class=\"hljs-number\">0.1</span>,\n",
      "    fp16=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Set to False if GPU can't handle FP16</span>\n",
      "    bf16=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Set to True if GPU supports BF16</span>\n",
      "    batch_sampler=BatchSamplers.NO_DUPLICATES,  <span class=\"hljs-comment\"># MultipleNegativesRankingLoss benefits from no duplicates</span>\n",
      "    <span class=\"hljs-comment\"># Optional tracking/debugging parameters:</span>\n",
      "    eval_strategy=<span class=\"hljs-string\">\"steps\"</span>,\n",
      "    eval_steps=<span class=\"hljs-number\">100</span>,\n",
      "    save_strategy=<span class=\"hljs-string\">\"steps\"</span>,\n",
      "    save_steps=<span class=\"hljs-number\">100</span>,\n",
      "    save_total_limit=<span class=\"hljs-number\">2</span>,\n",
      "    logging_steps=<span class=\"hljs-number\">100</span>,\n",
      "    run_name=<span class=\"hljs-string\">\"mpnet-base-all-nli-triplet\"</span>,  <span class=\"hljs-comment\"># Used in W&amp;B if `wandb` is installed</span>\n",
      ")\n",
      "\n",
      "<span class=\"hljs-comment\"># 6. (Optional) Create an evaluator &amp; evaluate the base model</span>\n",
      "dev_evaluator = TripletEvaluator(\n",
      "    anchors=eval_dataset[<span class=\"hljs-string\">\"anchor\"</span>],\n",
      "    positives=eval_dataset[<span class=\"hljs-string\">\"positive\"</span>],\n",
      "    negatives=eval_dataset[<span class=\"hljs-string\">\"negative\"</span>],\n",
      "    name=<span class=\"hljs-string\">\"all-nli-dev\"</span>,\n",
      ")\n",
      "dev_evaluator(model)\n",
      "\n",
      "<span class=\"hljs-comment\"># 7. Create a trainer &amp; train</span>\n",
      "trainer = SentenceTransformerTrainer(\n",
      "    model=model,\n",
      "    args=args,\n",
      "    train_dataset=train_dataset,\n",
      "    eval_dataset=eval_dataset,\n",
      "    loss=loss,\n",
      "    evaluator=dev_evaluator,\n",
      ")\n",
      "trainer.train()\n",
      "\n",
      "<span class=\"hljs-comment\"># (Optional) Evaluate the trained model on the test set, after training completes</span>\n",
      "test_evaluator = TripletEvaluator(\n",
      "    anchors=test_dataset[<span class=\"hljs-string\">\"anchor\"</span>],\n",
      "    positives=test_dataset[<span class=\"hljs-string\">\"positive\"</span>],\n",
      "    negatives=test_dataset[<span class=\"hljs-string\">\"negative\"</span>],\n",
      "    name=<span class=\"hljs-string\">\"all-nli-test\"</span>,\n",
      ")\n",
      "test_evaluator(model)\n",
      "\n",
      "<span class=\"hljs-comment\"># 8. Save the trained model</span>\n",
      "model.save_pretrained(<span class=\"hljs-string\">\"models/mpnet-base-all-nli-triplet/final\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># 9. (Optional) Push it to the Hugging Face Hub</span>\n",
      "model.push_to_hub(<span class=\"hljs-string\">\"mpnet-base-all-nli-triplet\"</span>)\n",
      "</code></pre>\n",
      "<p>In this example I'm finetuning from <a href=\"https://huggingface.co/microsoft/mpnet-base\"><code>microsoft/mpnet-base</code></a>, a base model that is not yet a Sentence Transformer model. This requires more training data than finetuning an existing Sentence Transformer model, like <a href=\"https://huggingface.co/sentence-transformers/all-mpnet-base-v2\"><code>all-mpnet-base-v2</code></a>.</p>\n",
      "<p>After running this script, the <a href=\"https://huggingface.co/tomaarsen/mpnet-base-all-nli-triplet\">tomaarsen/mpnet-base-all-nli-triplet</a> model was uploaded for me. The triplet accuracy using cosine similarity, i.e. what percentage of the time <code>cosine_similarity(anchor, positive) &gt; cosine_similarity(anchor, negative)</code> is 90.04% for the development set and 91.5% for the testing set! For reference, the <a href=\"https://huggingface.co/microsoft/mpnet-base\"><code>microsoft/mpnet-base</code></a> model scored only 68.32% on the dev set before training.</p>\n",
      "<p>All of this information is stored in the automatically generated model card, including the base model, language, license, evaluation results, training &amp; evaluation dataset info, hyperparameters, training logs, and more. Without any effort, your uploaded models should contain all the information that your potential users would need to determine whether your model is suitable for them.</p>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#callbacks\" id=\"callbacks\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tCallbacks\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>The Sentence Transformers trainer supports various <a href=\"https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback\"><code>transformers.TrainerCallback</code></a> subclasses, including:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.WandbCallback\"><code>WandbCallback</code></a> for logging training metrics to W&amp;B if <code>wandb</code> is installed</li>\n",
      "<li><a href=\"https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.TensorBoardCallback\"><code>TensorBoardCallback</code></a> for logging training metrics to TensorBoard if <code>tensorboard</code> is accessible</li>\n",
      "<li><a href=\"https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.CodeCarbonCallback\"><code>CodeCarbonCallback</code></a> for tracking carbon emissions during training if <code>codecarbon</code> is installed</li>\n",
      "</ul>\n",
      "<p>These are automatically used without you having to specify anything, as long as the required dependency is installed.</p>\n",
      "<p>Refer to the <a href=\"https://huggingface.co/docs/transformers/en/main_classes/callback\">Transformers Callbacks documentation</a> for more information on these callbacks and how to create your own.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#multi-dataset-training\" id=\"multi-dataset-training\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tMulti-Dataset Training\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>Top-performing models are often trained using multiple datasets simultaneously. The <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer\"><code>SentenceTransformerTrainer</code></a> simplifies this process by allowing you to train with multiple datasets without converting them to the same format. You can even apply different loss functions to each dataset. Here are the steps for multi-dataset training:</p>\n",
      "<ol>\n",
      "<li>Use a dictionary of <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset\"><code>datasets.Dataset</code></a> instances (or a <a href=\"https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict\"><code>datasets.DatasetDict</code></a>) as the <code>train_dataset</code> and <code>eval_dataset</code>.</li>\n",
      "<li>(Optional) Use a dictionary of loss functions mapping dataset names to losses if you want to use different losses for different datasets.</li>\n",
      "</ol>\n",
      "<p>Each training/evaluation batch will contain samples from only one of the datasets. The order in which batches are sampled from the multiple datasets is determined by the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentence_transformers.training_args.MultiDatasetBatchSamplers\"><code>MultiDatasetBatchSamplers</code></a> enum, which can be passed to the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments\"><code>SentenceTransformersTrainingArguments</code></a> via <code>multi_dataset_batch_sampler</code>. The valid options are:</p>\n",
      "<ul>\n",
      "<li><code>MultiDatasetBatchSamplers.ROUND_ROBIN</code>: Samples from each dataset in a round-robin fashion until one is exhausted. This strategy may not use all samples from each dataset, but it ensures equal sampling from each dataset.</li>\n",
      "<li><code>MultiDatasetBatchSamplers.PROPORTIONAL</code> (default): Samples from each dataset proportionally to its size. This strategy ensures that all samples from each dataset are used, and larger datasets are sampled from more frequently.</li>\n",
      "</ul>\n",
      "<p>Multi-task training has proven to be highly effective. For instance, <a href=\"https://arxiv.org/pdf/2405.06932\">Huang et al. 2024</a> employed <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss\"><code>MultipleNegativesRankingLoss</code></a>, <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cosentloss\"><code>CoSENTLoss</code></a>, and a variation of <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss\"><code>MultipleNegativesRankingLoss</code></a> without in-batch negatives and only hard negatives to achieve state-of-the-art performance on Chinese. They also applied <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/losses.html#matryoshkaloss\"><code>MatryoshkaLoss</code></a> to enable the model to produce <a href=\"https://huggingface.co/blog/matryoshka\">Matryoshka Embeddings</a>.</p>\n",
      "<p>Here's an example of multi-dataset training:</p>\n",
      "<pre><code class=\"language-python\"><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers <span class=\"hljs-keyword\">import</span> SentenceTransformer, SentenceTransformerTrainer\n",
      "<span class=\"hljs-keyword\">from</span> sentence_transformers.losses <span class=\"hljs-keyword\">import</span> CoSENTLoss, MultipleNegativesRankingLoss, SoftmaxLoss\n",
      "\n",
      "<span class=\"hljs-comment\"># 1. Load a model to finetune</span>\n",
      "model = SentenceTransformer(<span class=\"hljs-string\">\"bert-base-uncased\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># 2. Loadseveral Datasets to train with</span>\n",
      "<span class=\"hljs-comment\"># (anchor, positive)</span>\n",
      "all_nli_pair_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (premise, hypothesis) + label</span>\n",
      "all_nli_pair_class_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair-class\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (sentence1, sentence2) + score</span>\n",
      "all_nli_pair_score_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"pair-score\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (anchor, positive, negative)</span>\n",
      "all_nli_triplet_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"triplet\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (sentence1, sentence2) + score</span>\n",
      "stsb_pair_score_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/stsb\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (anchor, positive)</span>\n",
      "quora_pair_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/quora-duplicates\"</span>, <span class=\"hljs-string\">\"pair\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (query, answer)</span>\n",
      "natural_questions_train = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/natural-questions\"</span>, split=<span class=\"hljs-string\">\"train[:10000]\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># Combine all datasets into a dictionary with dataset names to datasets</span>\n",
      "train_dataset = {\n",
      "    <span class=\"hljs-string\">\"all-nli-pair\"</span>: all_nli_pair_train,\n",
      "    <span class=\"hljs-string\">\"all-nli-pair-class\"</span>: all_nli_pair_class_train,\n",
      "    <span class=\"hljs-string\">\"all-nli-pair-score\"</span>: all_nli_pair_score_train,\n",
      "    <span class=\"hljs-string\">\"all-nli-triplet\"</span>: all_nli_triplet_train,\n",
      "    <span class=\"hljs-string\">\"stsb\"</span>: stsb_pair_score_train,\n",
      "    <span class=\"hljs-string\">\"quora\"</span>: quora_pair_train,\n",
      "    <span class=\"hljs-string\">\"natural-questions\"</span>: natural_questions_train,\n",
      "}\n",
      "\n",
      "<span class=\"hljs-comment\"># 3. Load several Datasets to evaluate with</span>\n",
      "<span class=\"hljs-comment\"># (anchor, positive, negative)</span>\n",
      "all_nli_triplet_dev = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/all-nli\"</span>, <span class=\"hljs-string\">\"triplet\"</span>, split=<span class=\"hljs-string\">\"dev\"</span>)\n",
      "<span class=\"hljs-comment\"># (sentence1, sentence2, score)</span>\n",
      "stsb_pair_score_dev = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/stsb\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>)\n",
      "<span class=\"hljs-comment\"># (anchor, positive)</span>\n",
      "quora_pair_dev = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/quora-duplicates\"</span>, <span class=\"hljs-string\">\"pair\"</span>, split=<span class=\"hljs-string\">\"train[10000:11000]\"</span>)\n",
      "<span class=\"hljs-comment\"># (query, answer)</span>\n",
      "natural_questions_dev = load_dataset(<span class=\"hljs-string\">\"sentence-transformers/natural-questions\"</span>, split=<span class=\"hljs-string\">\"train[10000:11000]\"</span>)\n",
      "\n",
      "<span class=\"hljs-comment\"># Use a dictionary for the evaluation dataset too, or just use one dataset or none at all</span>\n",
      "eval_dataset = {\n",
      "    <span class=\"hljs-string\">\"all-nli-triplet\"</span>: all_nli_triplet_dev,\n",
      "    <span class=\"hljs-string\">\"stsb\"</span>: stsb_pair_score_dev,\n",
      "    <span class=\"hljs-string\">\"quora\"</span>: quora_pair_dev,\n",
      "    <span class=\"hljs-string\">\"natural-questions\"</span>: natural_questions_dev,\n",
      "}\n",
      "\n",
      "<span class=\"hljs-comment\"># 4. Load several loss functions to train with</span>\n",
      "<span class=\"hljs-comment\"># (anchor, positive), (anchor, positive, negative)</span>\n",
      "mnrl_loss = MultipleNegativesRankingLoss(model)\n",
      "<span class=\"hljs-comment\"># (sentence_A, sentence_B) + class</span>\n",
      "softmax_loss = SoftmaxLoss(model)\n",
      "<span class=\"hljs-comment\"># (sentence_A, sentence_B) + score</span>\n",
      "cosent_loss = CoSENTLoss(model)\n",
      "\n",
      "<span class=\"hljs-comment\"># Create a mapping with dataset names to loss functions, so the trainer knows which loss to apply where</span>\n",
      "<span class=\"hljs-comment\"># Note: You can also just use one loss if all your training/evaluation datasets use the same loss</span>\n",
      "losses = {\n",
      "    <span class=\"hljs-string\">\"all-nli-pair\"</span>: mnrl_loss,\n",
      "    <span class=\"hljs-string\">\"all-nli-pair-class\"</span>: softmax_loss,\n",
      "    <span class=\"hljs-string\">\"all-nli-pair-score\"</span>: cosent_loss,\n",
      "    <span class=\"hljs-string\">\"all-nli-triplet\"</span>: mnrl_loss,\n",
      "    <span class=\"hljs-string\">\"stsb\"</span>: cosent_loss,\n",
      "    <span class=\"hljs-string\">\"quora\"</span>: mnrl_loss,\n",
      "    <span class=\"hljs-string\">\"natural-questions\"</span>: mnrl_loss,\n",
      "}\n",
      "\n",
      "<span class=\"hljs-comment\"># 5. Define a simple trainer, although it's recommended to use one with args &amp; evaluators</span>\n",
      "trainer = SentenceTransformerTrainer(\n",
      "    model=model,\n",
      "    train_dataset=train_dataset,\n",
      "    eval_dataset=eval_dataset,\n",
      "    loss=losses,\n",
      ")\n",
      "trainer.train()\n",
      "\n",
      "<span class=\"hljs-comment\"># 6. Save the trained model and optionally push it to the Hugging Face Hub</span>\n",
      "model.save_pretrained(<span class=\"hljs-string\">\"bert-base-all-nli-stsb-quora-nq\"</span>)\n",
      "model.push_to_hub(<span class=\"hljs-string\">\"bert-base-all-nli-stsb-quora-nq\"</span>)\n",
      "</code></pre>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#deprecation\" id=\"deprecation\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tDeprecation\n",
      "\t</span>\n",
      "</h2>\n",
      "<p>Prior to the Sentence Transformer v3 release, all models would be trained using the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.fit\"><code>SentenceTransformer.fit</code></a> method. Rather than deprecating this method, starting from v3.0, this method will use the <a href=\"https://sbert.net/docs/package_reference/sentence_transformer/trainer.html#sentence_transformers.trainer.SentenceTransformerTrainer\"><code>SentenceTransformerTrainer</code></a> behind the scenes. This means that your old training code should still work, and should even be upgraded with the new features such as multi-gpu training, loss logging, etc. That said, the new training approach is much more powerful, so it is <strong>recommended</strong> to write new training scripts using the new approach.</p>\n",
      "<h2 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#additional-resources\" id=\"additional-resources\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tAdditional Resources\n",
      "\t</span>\n",
      "</h2>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#training-examples\" id=\"training-examples\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tTraining Examples\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>The following pages contain training examples with explanations as well as links to code. We recommend that you browse through these to familiarize yourself with the training loop:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://sbert.net/examples/training/sts/README.html\">Semantic Textual Similarity</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/nli/README.html\">Natural Language Inference</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/paraphrases/README.html\">Paraphrases</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/quora_duplicate_questions/README.html\">Quora Duplicate Questions</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/matryoshka/README.html\">Matryoshka Embeddings</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/adaptive_layer/README.html\">Adaptive Layer Models</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/multilingual/README.html\">Multilingual Models</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/distillation/README.html\">Model Distillation</a></li>\n",
      "<li><a href=\"https://sbert.net/examples/training/data_augmentation/README.html\">Augmented Sentence Transformers</a></li>\n",
      "</ul>\n",
      "<h3 class=\"relative group flex items-center\">\n",
      "<a class=\"block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full\" href=\"#documentation\" id=\"documentation\">\n",
      "<span class=\"header-link\"><svg aria-hidden=\"true\" class=\"text-gray-500 hover:text-black dark:hover:text-gray-200 w-4\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span>\n",
      "</a>\n",
      "<span>\n",
      "\t\tDocumentation\n",
      "\t</span>\n",
      "</h3>\n",
      "<p>Additionally, the following pages may be useful to learn more about Sentence Transformers:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://sbert.net/docs/installation.html\">Installation</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/quickstart.html\">Quickstart</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/usage/usage.html\">Usage</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/pretrained_models.html\">Pretrained Models</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/training_overview.html\">Training Overview</a> (This blogpost is a distillation of the Training Overiew documentation)</li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/dataset_overview.html\">Dataset Overview</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/loss_overview.html\">Loss Overview</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/package_reference/sentence_transformer/index.html\">API Reference</a></li>\n",
      "</ul>\n",
      "<p>And lastly, here are some advanced pages that might interest you:</p>\n",
      "<ul>\n",
      "<li><a href=\"https://sbert.net/examples/training/hpo/README.html\">Hyperparameter Optimization</a></li>\n",
      "<li><a href=\"https://sbert.net/docs/sentence_transformer/training/distributed.html\">Distributed Training</a></li>\n",
      "</ul>\n",
      "<!-- HTML_TAG_END --></div>\n",
      "<div class=\"mx-auto max-w-5xl border-t border-gray-200 py-16\"><div class=\"container grid gap-4 py-8\"><div class=\"grid gap-6 md:grid-cols-2\"><p class=\"col-span-1 mb-6 text-center text-lg font-semibold md:col-span-2\">More Articles from our Blog</p>\n",
      "<div class=\"SVELTE_HYDRATER contents\" data-props='{\"blog\":{\"authors\":[{\"user\":\"Xenova\"},{\"user\":\"pcuenq\"},{\"user\":\"reach-vb\"},{\"user\":\"joaogante\"}],\"canonical\":true,\"isUpvotedByUser\":false,\"publishedAt\":\"2024-07-31T00:00:00.000Z\",\"slug\":\"gemma-july-update\",\"title\":\"Google releases Gemma 2 2B, ShieldGemma and Gemma Scope\",\"upvotes\":51,\"thumbnail\":\"/blog/assets/gemma-july-update/thumbnail.jpg\"},\"blogUrl\":\"/blog\",\"lang\":\"en\"}' data-target=\"BlogThumbnail\"><a class=\"flex lg:col-span-1 hover:shadow-alternate group relative flex-col overflow-hidden rounded-xl border border-gray-100 shadow-sm transition-shadow\" href=\"/blog/gemma-july-update\"><div class=\"aspect-[1.91/1] w-full rounded-b shadow-alternate relative flex-none overflow-hidden rounded-lg bg-white\"><div class=\"absolute inset-0 group-hover:opacity-40 dark:backdrop-brightness-105\"></div>\n",
      "<img alt=\"\" class=\"h-full w-full object-cover group-hover:brightness-110\" src=\"/blog/assets/gemma-july-update/thumbnail.jpg\"/></div>\n",
      "<div class=\"flex flex-col p-4\"><h2 class=\"font-serif font-semibold group-hover:underline text-xl\">Google releases Gemma 2 2B, ShieldGemma and Gemma Scope</h2>\n",
      "<p class=\"mt-3 flex flex-wrap items-center gap-y-1.5 font-mono text-xs text-gray-500\">\n",
      "\t\t\t\tBy <object title=\"\">\n",
      "<span class=\"inline-block\"><span class=\"contents\"><a class=\"hover:underline\" href=\"/Xenova\">Xenova</a></span>\n",
      "</span></object>\n",
      "<span class=\"mx-2 h-1 w-1 flex-none bg-gray-200\"></span>\n",
      "<span>July 31, 2024</span>\n",
      "<span class=\"px-1.5 text-gray-300\">•</span>\n",
      "<svg aria-hidden=\"true\" class=\"flex-none w-3 mr-1 text-gray-400\" fill=\"transparent\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 12 12\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z\" stroke=\"currentColor\"></path></svg>\n",
      "\n",
      "\t\t\t\t51</p></div></a></div><div class=\"SVELTE_HYDRATER contents\" data-props='{\"blog\":{\"authors\":[{\"user\":\"philschmid\"},{\"user\":\"osanseviero\"},{\"user\":\"alvarobartt\"},{\"user\":\"lvwerra\"},{\"user\":\"dvilasuero\"},{\"user\":\"reach-vb\"},{\"user\":\"marcsun13\"},{\"user\":\"pcuenq\"}],\"canonical\":true,\"isUpvotedByUser\":false,\"publishedAt\":\"2024-07-23T00:00:00.000Z\",\"slug\":\"llama31\",\"title\":\"Llama 3.1 - 405B, 70B &amp; 8B with multilinguality and long context\",\"upvotes\":146,\"thumbnail\":\"/blog/assets/llama31/thumbnail.jpg\"},\"blogUrl\":\"/blog\",\"lang\":\"en\"}' data-target=\"BlogThumbnail\"><a class=\"flex lg:col-span-1 hover:shadow-alternate group relative flex-col overflow-hidden rounded-xl border border-gray-100 shadow-sm transition-shadow\" href=\"/blog/llama31\"><div class=\"aspect-[1.91/1] w-full rounded-b shadow-alternate relative flex-none overflow-hidden rounded-lg bg-white\"><div class=\"absolute inset-0 group-hover:opacity-40 dark:backdrop-brightness-105\"></div>\n",
      "<img alt=\"\" class=\"h-full w-full object-cover group-hover:brightness-110\" src=\"/blog/assets/llama31/thumbnail.jpg\"/></div>\n",
      "<div class=\"flex flex-col p-4\"><h2 class=\"font-serif font-semibold group-hover:underline text-xl\">Llama 3.1 - 405B, 70B &amp; 8B with multilinguality and long context</h2>\n",
      "<p class=\"mt-3 flex flex-wrap items-center gap-y-1.5 font-mono text-xs text-gray-500\">\n",
      "\t\t\t\tBy <object title=\"\">\n",
      "<span class=\"inline-block\"><span class=\"contents\"><a class=\"hover:underline\" href=\"/philschmid\">philschmid</a></span>\n",
      "</span></object>\n",
      "<span class=\"mx-2 h-1 w-1 flex-none bg-gray-200\"></span>\n",
      "<span>July 23, 2024</span>\n",
      "<span class=\"px-1.5 text-gray-300\">•</span>\n",
      "<svg aria-hidden=\"true\" class=\"flex-none w-3 mr-1 text-gray-400\" fill=\"transparent\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 12 12\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z\" stroke=\"currentColor\"></path></svg>\n",
      "\n",
      "\t\t\t\t146</p></div></a></div></div></div></div></div>\n",
      "<div class=\"w-56 flex-none pt-28 max-lg:hidden\"><div class=\"SVELTE_HYDRATER contents\" data-props='{\"classNames\":\"lg:max-w-60 lg:flex-col lg:!items-start\",\"maxShown\":12,\"apiUrlPrefix\":\"/api/blog/train-sentence-transformers\",\"postLoginRedirectUrl\":\"/blog/train-sentence-transformers\",\"style\":\"horizontal\",\"color\":\"gray\",\"upvotedColor\":\"orange\",\"upvoted\":false,\"upvoters\":[{\"_id\":\"5dfb0c8bda6d0311fd3d5434\",\"avatarUrl\":\"/avatars/67cf91ea59ad44c7080f1d99537e974d.svg\",\"isPro\":false,\"fullname\":\"Takatsugu Nokubi\",\"user\":\"knok\",\"type\":\"user\"},{\"_id\":\"5e0eed1ffcf41d740b699666\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e0eed1ffcf41d740b699666/jJnkTB9wsP4QBcIRZqZFD.jpeg\",\"isPro\":false,\"fullname\":\"Blanc Swan\",\"user\":\"blancsw\",\"type\":\"user\"},{\"_id\":\"5e56829137cb5b49818287ea\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e56829137cb5b49818287ea/8HYzJeRc4b9Wu7BfJwibS.png\",\"isPro\":false,\"fullname\":\"Lee Junbum\",\"user\":\"beomi\",\"type\":\"user\"},{\"_id\":\"5e9b38f84957053f60648a2d\",\"avatarUrl\":\"/avatars/dc487fced46eacee93f96b6c966c8912.svg\",\"isPro\":false,\"fullname\":\"vijay G\",\"user\":\"vijayg\",\"type\":\"user\"},{\"_id\":\"5ea4f7a7ba91ce67ad45a95e\",\"avatarUrl\":\"/avatars/93703e565323afcd226a76cf6baeb0f7.svg\",\"isPro\":false,\"fullname\":\"Nick Doiron\",\"user\":\"monsoon-nlp\",\"type\":\"user\"},{\"_id\":\"5f353bb37e58354338621655\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg\",\"isPro\":true,\"fullname\":\"Nicholas Broad\",\"user\":\"nbroad\",\"type\":\"user\"},{\"_id\":\"5f4066e079c1ba4c353d0c75\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png\",\"isPro\":false,\"fullname\":\"Snehal\",\"user\":\"spate141\",\"type\":\"user\"},{\"_id\":\"5f43d8ac79c1ba4c353d0df2\",\"avatarUrl\":\"/avatars/2b23d9444bd39d39d4c912d520bac4c8.svg\",\"isPro\":false,\"fullname\":\"AJ\",\"user\":\"Buckeyes2019\",\"type\":\"user\"},{\"_id\":\"5ff5d596f244529b3ec0fb89\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png\",\"isPro\":false,\"fullname\":\"Philipp Schmid\",\"user\":\"philschmid\",\"type\":\"user\"},{\"_id\":\"60107b385ac3e86b3ea4fc34\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg\",\"isPro\":true,\"fullname\":\"Daniel van Strien\",\"user\":\"davanstrien\",\"type\":\"user\"},{\"_id\":\"60196690dd31fde3c1062960\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/1612277330660-noauth.jpeg\",\"isPro\":false,\"fullname\":\"Nandan Thakur\",\"user\":\"nthakur\",\"type\":\"user\"},{\"_id\":\"6032802e1f993496bc14d9e3\",\"avatarUrl\":\"https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png\",\"isPro\":false,\"fullname\":\"Omar Sanseviero\",\"user\":\"osanseviero\",\"type\":\"user\"}],\"upvotes\":131}' data-target=\"UpvoteControl\"><div class=\"flex flex-wrap items-center gap-2.5 pt-1 lg:max-w-60 lg:flex-col lg:!items-start\"><a class=\"self-start\" href=\"/login?next=%2Fblog%2Ftrain-sentence-transformers\"><div class=\"shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850\"><input class=\"peer hidden\" disabled=\"\" type=\"checkbox\"/>\n",
      "<svg aria-hidden=\"true\" class=\"text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 12 12\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z\" fill=\"currentColor\"></path></svg>\n",
      "\t\tUpvote\n",
      "\n",
      "\t\t<div class=\"font-semibold text-orange-500\">131</div></div>\n",
      "</a>\n",
      "<ul class=\"flex items-center flex-row text-base\"><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"knok\"><a href=\"/knok\" title=\"knok\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/67cf91ea59ad44c7080f1d99537e974d.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"blancsw\"><a href=\"/blancsw\" title=\"blancsw\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e0eed1ffcf41d740b699666/jJnkTB9wsP4QBcIRZqZFD.jpeg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"beomi\"><a href=\"/beomi\" title=\"beomi\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/5e56829137cb5b49818287ea/8HYzJeRc4b9Wu7BfJwibS.png\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"vijayg\"><a href=\"/vijayg\" title=\"vijayg\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/dc487fced46eacee93f96b6c966c8912.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"monsoon-nlp\"><a href=\"/monsoon-nlp\" title=\"monsoon-nlp\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/93703e565323afcd226a76cf6baeb0f7.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"nbroad\"><a href=\"/nbroad\" title=\"nbroad\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1639773384591-5f353bb37e58354338621655.jpeg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"spate141\"><a href=\"/spate141\" title=\"spate141\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1654555959564-5f4066e079c1ba4c353d0c75.png\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"Buckeyes2019\"><a href=\"/Buckeyes2019\" title=\"Buckeyes2019\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"/avatars/2b23d9444bd39d39d4c912d520bac4c8.svg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"philschmid\"><a href=\"/philschmid\" title=\"philschmid\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"davanstrien\"><a href=\"/davanstrien\" title=\"davanstrien\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"nthakur\"><a href=\"/nthakur\" title=\"nthakur\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/1612277330660-noauth.jpeg\"/>\n",
      "</a>\n",
      "</li><li class=\"-mr-2 h-5 w-5 md:h-6 md:w-6 block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800\" style=\"content-visibility:auto;\" title=\"osanseviero\"><a href=\"/osanseviero\" title=\"osanseviero\"><img alt=\"\" class=\"overflow-hidden rounded-full\" src=\"https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png\"/>\n",
      "</a>\n",
      "</li>\n",
      "<li class=\"text-gray-600 hover:text-gray-700 order-last ml-3\"><button class=\"btn -ml-3 translate-x-px rounded-full border-2 border-white bg-gradient-to-br px-1.5 py-0.5 text-xs\">+119</button></li></ul></div>\n",
      "</div></div></div></main>\n",
      "<footer class=\"b-12 mb-2 flex border-t border-gray-100 md:h-14\"><nav class=\"container flex flex-col justify-between space-y-2 py-6 text-gray-500 md:flex-row md:items-center md:space-y-0 md:py-0 md:text-sm\"><div class=\"font-semibold text-black md:hidden\">Company</div>\n",
      "<div class=\"order-last pt-6 text-gray-400 md:order-none md:pt-0\" href=\"Terms\">© Hugging Face</div>\n",
      "<a class=\"hover:underline\" href=\"/terms-of-service\">TOS</a>\n",
      "<a class=\"hover:underline\" href=\"/privacy\">Privacy</a>\n",
      "<a class=\"hover:underline\" href=\"/huggingface\">About</a>\n",
      "<a class=\"hover:underline\" href=\"https://apply.workable.com/huggingface/\">Jobs</a>\n",
      "<a class=\"group order-first flex-none pb-6 md:order-none md:pb-0\" href=\"/\"><svg class=\"h-7 w-7 transition-transform group-hover:-translate-y-px\" fill=\"none\" viewbox=\"0 0 95 88\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5Z\" fill=\"#FFD21E\"></path><path d=\"M81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75ZM8.46185 41.75C8.46185 20.349 25.8108 3 47.2119 3C68.6129 3 85.9619 20.349 85.9619 41.75C85.9619 63.151 68.6129 80.5 47.2119 80.5C25.8108 80.5 8.46185 63.151 8.46185 41.75Z\" fill=\"#FF9D0B\"></path><path d=\"M58.5024 32.2915C59.7768 32.7415 60.2839 35.3615 61.5713 34.6769C64.0095 33.3805 64.9351 30.353 63.6387 27.9148C62.3423 25.4767 59.3148 24.5511 56.8766 25.8475C54.4384 27.1439 53.5128 30.1714 54.8092 32.6096C55.4211 33.7604 57.3632 31.8892 58.5024 32.2915Z\" fill=\"#3A3B45\"></path><path d=\"M34.9454 32.2915C33.671 32.7415 33.164 35.3615 31.8766 34.6769C29.4384 33.3805 28.5128 30.353 29.8092 27.9148C31.1056 25.4767 34.1331 24.5511 36.5713 25.8475C39.0095 27.1439 39.9351 30.1714 38.6387 32.6096C38.0268 33.7604 36.0846 31.8892 34.9454 32.2915Z\" fill=\"#3A3B45\"></path><path d=\"M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z\" fill=\"#3A3B45\"></path><mask height=\"16\" id=\"mask0\" mask-type=\"alpha\" maskunits=\"userSpaceOnUse\" width=\"27\" x=\"33\" y=\"41\"><path d=\"M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z\" fill=\"white\"></path></mask><g mask=\"url(#mask0)\"><path d=\"M47.2119 66.5C52.0018 66.5 55.8848 62.617 55.8848 57.8271C55.8848 54.0962 53.5291 50.9156 50.224 49.6915C50.1023 49.6464 49.9794 49.604 49.8553 49.5643C49.0219 49.2979 48.1337 52.1623 47.2119 52.1623C46.3506 52.1623 45.5186 49.2797 44.7332 49.5135C41.151 50.5799 38.5389 53.8984 38.5389 57.8271C38.5389 62.617 42.4219 66.5 47.2119 66.5Z\" fill=\"#F94040\"></path></g><path d=\"M70.7119 37C72.5068 37 73.9619 35.5449 73.9619 33.75C73.9619 31.9551 72.5068 30.5 70.7119 30.5C68.9169 30.5 67.4619 31.9551 67.4619 33.75C67.4619 35.5449 68.9169 37 70.7119 37Z\" fill=\"#FF9D0B\"></path><path d=\"M24.2119 37C26.0068 37 27.4619 35.5449 27.4619 33.75C27.4619 31.9551 26.0068 30.5 24.2119 30.5C22.4169 30.5 20.9619 31.9551 20.9619 33.75C20.9619 35.5449 22.4169 37 24.2119 37Z\" fill=\"#FF9D0B\"></path><path class=\"origin-bottom-right transition-transform group-hover:-rotate-6\" d=\"M17.5238 48C15.9048 48 14.4578 48.665 13.4488 49.871C12.8248 50.618 12.1728 51.822 12.1198 53.625C11.4408 53.43 10.7878 53.321 10.1778 53.321C8.6278 53.321 7.2278 53.915 6.2378 54.994C4.9658 56.379 4.4008 58.081 4.6468 59.784C4.7638 60.595 5.0348 61.322 5.4398 61.995C4.5858 62.686 3.9568 63.648 3.6528 64.805C3.4148 65.712 3.1708 67.601 4.4448 69.547C4.3638 69.674 4.2878 69.806 4.2168 69.941C3.4508 71.395 3.4018 73.038 4.0778 74.568C5.1028 76.887 7.6498 78.714 12.5958 80.675C15.6728 81.895 18.4878 82.675 18.5128 82.682C22.5808 83.737 26.2598 84.273 29.4448 84.273C35.2988 84.273 39.4898 82.48 41.9018 78.944C45.7838 73.25 45.2288 68.042 40.2058 63.022C37.4258 60.244 35.5778 56.148 35.1928 55.249C34.4168 52.587 32.3648 49.628 28.9538 49.628H28.9528C28.6658 49.628 28.3758 49.651 28.0898 49.696C26.5958 49.931 25.2898 50.791 24.3568 52.085C23.3498 50.833 22.3718 49.837 21.4868 49.275C20.1528 48.429 18.8198 48 17.5238 48ZM17.5238 52C18.0338 52 18.6568 52.217 19.3438 52.653C21.4768 54.006 25.5928 61.081 27.0998 63.833C27.6048 64.755 28.4678 65.145 29.2448 65.145C30.7868 65.145 31.9908 63.612 29.3858 61.664C25.4688 58.733 26.8428 53.942 28.7128 53.647C28.7948 53.634 28.8758 53.628 28.9538 53.628C30.6538 53.628 31.4038 56.558 31.4038 56.558C31.4038 56.558 33.6018 62.078 37.3778 65.851C41.1538 69.625 41.3488 72.654 38.5968 76.69C36.7198 79.442 33.1268 80.273 29.4448 80.273C25.6258 80.273 21.7108 79.379 19.5168 78.81C19.4088 78.782 6.0658 75.013 7.7558 71.805C8.0398 71.266 8.5078 71.05 9.0968 71.05C11.4768 71.05 15.8058 74.592 17.6668 74.592C18.0828 74.592 18.3758 74.415 18.4958 73.983C19.2888 71.138 6.4388 69.942 7.5218 65.821C7.7128 65.092 8.2308 64.796 8.9588 64.797C12.1038 64.797 19.1598 70.328 20.6388 70.328C20.7518 70.328 20.8328 70.295 20.8768 70.225C21.6178 69.029 21.2118 68.194 15.9888 65.033C10.7658 61.871 7.0998 59.969 9.1848 57.699C9.4248 57.437 9.7648 57.321 10.1778 57.321C13.3488 57.322 20.8408 64.14 20.8408 64.14C20.8408 64.14 22.8628 66.243 24.0858 66.243C24.3668 66.243 24.6058 66.132 24.7678 65.858C25.6348 64.396 16.7148 57.636 16.2118 54.847C15.8708 52.957 16.4508 52 17.5238 52Z\" fill=\"#FF9D0B\"></path><path class=\"origin-bottom-right transition-transform group-hover:-rotate-6\" d=\"M38.5967 76.6898C41.3487 72.6538 41.1537 69.6248 37.3777 65.8508C33.6017 62.0778 31.4037 56.5578 31.4037 56.5578C31.4037 56.5578 30.5827 53.3518 28.7127 53.6468C26.8427 53.9418 25.4697 58.7328 29.3867 61.6638C33.3037 64.5938 28.6067 66.5848 27.0997 63.8328C25.5927 61.0808 21.4777 54.0058 19.3437 52.6528C17.2107 51.2998 15.7087 52.0578 16.2117 54.8468C16.7147 57.6358 25.6357 64.3958 24.7677 65.8588C23.8997 67.3208 20.8407 64.1398 20.8407 64.1398C20.8407 64.1398 11.2687 55.4288 9.18465 57.6988C7.10065 59.9688 10.7657 61.8708 15.9887 65.0328C21.2127 68.1938 21.6177 69.0288 20.8767 70.2248C20.1347 71.4208 8.60465 61.6998 7.52165 65.8208C6.43965 69.9418 19.2887 71.1378 18.4957 73.9828C17.7027 76.8288 9.44465 68.5978 7.75565 71.8048C6.06565 75.0128 19.4087 78.7818 19.5167 78.8098C23.8267 79.9278 34.7727 82.2968 38.5967 76.6898Z\" fill=\"#FFD21E\"></path><path class=\"origin-bottom-left transition-transform group-hover:rotate-6\" d=\"M77.3999 48C79.0189 48 80.4659 48.665 81.4749 49.871C82.0989 50.618 82.7509 51.822 82.8039 53.625C83.4829 53.43 84.1359 53.321 84.7459 53.321C86.2959 53.321 87.6959 53.915 88.6859 54.994C89.9579 56.379 90.5229 58.081 90.2769 59.784C90.1599 60.595 89.8889 61.322 89.4839 61.995C90.3379 62.686 90.9669 63.648 91.2709 64.805C91.5089 65.712 91.7529 67.601 90.4789 69.547C90.5599 69.674 90.6359 69.806 90.7069 69.941C91.4729 71.395 91.5219 73.038 90.8459 74.568C89.8209 76.887 87.2739 78.714 82.3279 80.675C79.2509 81.895 76.4359 82.675 76.4109 82.682C72.3429 83.737 68.6639 84.273 65.4789 84.273C59.6249 84.273 55.4339 82.48 53.0219 78.944C49.1399 73.25 49.6949 68.042 54.7179 63.022C57.4979 60.244 59.3459 56.148 59.7309 55.249C60.5069 52.587 62.5589 49.628 65.9699 49.628H65.9709C66.2579 49.628 66.5479 49.651 66.8339 49.696C68.3279 49.931 69.6339 50.791 70.5669 52.085C71.5739 50.833 72.5519 49.837 73.4369 49.275C74.7709 48.429 76.1039 48 77.3999 48ZM77.3999 52C76.8899 52 76.2669 52.217 75.5799 52.653C73.4469 54.006 69.3309 61.081 67.8239 63.833C67.3189 64.755 66.4559 65.145 65.6789 65.145C64.1369 65.145 62.9329 63.612 65.5379 61.664C69.4549 58.733 68.0809 53.942 66.2109 53.647C66.1289 53.634 66.0479 53.628 65.9699 53.628C64.2699 53.628 63.5199 56.558 63.5199 56.558C63.5199 56.558 61.3219 62.078 57.5459 65.851C53.7699 69.625 53.5749 72.654 56.3269 76.69C58.2039 79.442 61.7969 80.273 65.4789 80.273C69.2979 80.273 73.2129 79.379 75.4069 78.81C75.5149 78.782 88.8579 75.013 87.1679 71.805C86.8839 71.266 86.4159 71.05 85.8269 71.05C83.4469 71.05 79.1179 74.592 77.2569 74.592C76.8409 74.592 76.5479 74.415 76.4279 73.983C75.6349 71.138 88.4849 69.942 87.4019 65.821C87.2109 65.092 86.6929 64.796 85.9649 64.797C82.8199 64.797 75.7639 70.328 74.2849 70.328C74.1719 70.328 74.0909 70.295 74.0469 70.225C73.3059 69.029 73.7119 68.194 78.9349 65.033C84.1579 61.871 87.8239 59.969 85.7389 57.699C85.4989 57.437 85.1589 57.321 84.7459 57.321C81.5749 57.322 74.0829 64.14 74.0829 64.14C74.0829 64.14 72.0609 66.243 70.8379 66.243C70.5569 66.243 70.3179 66.132 70.1559 65.858C69.2889 64.396 78.2089 57.636 78.7119 54.847C79.0529 52.957 78.4729 52 77.3999 52Z\" fill=\"#FF9D0B\"></path><path class=\"origin-bottom-left transition-transform group-hover:rotate-6\" d=\"M56.3271 76.6898C53.5751 72.6538 53.7701 69.6248 57.5461 65.8508C61.3221 62.0778 63.5201 56.5578 63.5201 56.5578C63.5201 56.5578 64.3411 53.3518 66.2111 53.6468C68.0811 53.9418 69.4541 58.7328 65.5371 61.6638C61.6201 64.5938 66.3171 66.5848 67.8241 63.8328C69.3311 61.0808 73.4461 54.0058 75.5801 52.6528C77.7131 51.2998 79.2151 52.0578 78.7121 54.8468C78.2091 57.6358 69.2881 64.3958 70.1561 65.8588C71.0241 67.3208 74.0831 64.1398 74.0831 64.1398C74.0831 64.1398 83.6551 55.4288 85.7391 57.6988C87.8231 59.9688 84.1581 61.8708 78.9351 65.0328C73.7111 68.1938 73.3061 69.0288 74.0471 70.2248C74.7891 71.4208 86.3191 61.6998 87.4021 65.8208C88.4841 69.9418 75.6351 71.1378 76.4281 73.9828C77.2211 76.8288 85.4791 68.5978 87.1681 71.8048C88.8581 75.0128 75.5151 78.7818 75.4071 78.8098C71.0971 79.9278 60.1511 82.2968 56.3271 76.6898Z\" fill=\"#FFD21E\"></path></svg></a>\n",
      "<div class=\"pt-6 font-semibold text-black md:hidden md:pt-0\">Website</div>\n",
      "<a class=\"hover:underline\" href=\"/models\">Models</a>\n",
      "<a class=\"hover:underline\" href=\"/datasets\">Datasets</a>\n",
      "<a class=\"hover:underline\" href=\"/spaces\">Spaces</a>\n",
      "<a class=\"hover:underline\" href=\"/pricing\">Pricing</a>\n",
      "<a class=\"hover:underline\" href=\"/docs\">Docs</a></nav></footer></div>\n",
      "<script>\n",
      "\t\t\timport(\"/front/build/kube-0932549/index.js\");\n",
      "\t\t\twindow.moonSha = \"kube-0932549/\";\n",
      "\t\t</script>\n",
      "<!-- Stripe -->\n",
      "<script>\n",
      "\t\t\tif ([\"hf.co\", \"huggingface.co\"].includes(window.location.hostname)) {\n",
      "\t\t\t\tconst script = document.createElement(\"script\");\n",
      "\t\t\t\tscript.src = \"https://js.stripe.com/v3/\";\n",
      "\t\t\t\tscript.async = true;\n",
      "\t\t\t\tdocument.head.appendChild(script);\n",
      "\t\t\t}\n",
      "\t\t</script>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://huggingface.co/blog/train-sentence-transformers\"\n",
    "data = beautifulsoup_web_scrape_url(url)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/2310.19923v4\"\n",
    "pdf_data = beautifulsoup_web_scrape_url(pdf_url)\n",
    "print(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jinaai_readerapi_web_scrape_url(url):\n",
    "    response = requests.get(\"https://r.jina.ai/\" + url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Training and Finetuning Embedding Models with Sentence Transformers v3\n",
      "\n",
      "URL Source: https://huggingface.co/blog/train-sentence-transformers\n",
      "\n",
      "Markdown Content:\n",
      "[Back to Articles](https://huggingface.co/blog)\n",
      "\n",
      "[![Image 1: Tom Aarsen's avatar](https://cdn-avatars.huggingface.co/v1/production/uploads/6317233cc92fd6fee317e030/cJHSvvimr1kqgQfHOjO5n.png)](https://huggingface.co/tomaarsen)\n",
      "\n",
      "[Sentence Transformers](https://sbert.net/) is a Python library for using and training embedding models for a wide range of applications, such as retrieval augmented generation, semantic search, semantic textual similarity, paraphrase mining, and more. Its v3.0 update is the largest since the project's inception, introducing a new training approach. In this blogpost, I'll show you how to use it to finetune Sentence Transformer models to improve their performance on specific tasks. You can also use this method to train new Sentence Transformer models from scratch.\n",
      "\n",
      "Finetuning Sentence Transformers now involves several components, including datasets, loss functions, training arguments, evaluators, and the new trainer itself. I'll go through each of these components in detail and provide examples of how to use them to train effective models.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#table-of-contents)Table of Contents\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "*   [Why Finetune?](https://huggingface.co/blog/train-sentence-transformers#why-finetune)\n",
      "*   [Training Components](https://huggingface.co/blog/train-sentence-transformers#training-components)\n",
      "*   [Dataset](https://huggingface.co/blog/train-sentence-transformers#dataset)\n",
      "    *   [Data on Hugging Face Hub](https://huggingface.co/blog/train-sentence-transformers#data-on-hugging-face-hub)\n",
      "    *   [Local Data (CSV, JSON, Parquet, Arrow, SQL)](https://huggingface.co/blog/train-sentence-transformers#local-data-csv-json-parquet-arrow-sql)\n",
      "    *   [Local Data that requires pre-processing](https://huggingface.co/blog/train-sentence-transformers#local-data-that-requires-pre-processing)\n",
      "    *   [Dataset Format](https://huggingface.co/blog/train-sentence-transformers#dataset-format)\n",
      "*   [Loss Function](https://huggingface.co/blog/train-sentence-transformers#loss-function)\n",
      "*   [Training Arguments](https://huggingface.co/blog/train-sentence-transformers#training-arguments)\n",
      "*   [Evaluator](https://huggingface.co/blog/train-sentence-transformers#evaluator)\n",
      "    *   [EmbeddingSimilarityEvaluator with STSb](https://huggingface.co/blog/train-sentence-transformers#embeddingsimilarityevaluator-with-stsb)\n",
      "    *   [TripletEvaluator with AllNLI](https://huggingface.co/blog/train-sentence-transformers#tripletevaluator-with-allnli)\n",
      "*   [Trainer](https://huggingface.co/blog/train-sentence-transformers#trainer)\n",
      "    *   [Callbacks](https://huggingface.co/blog/train-sentence-transformers#callbacks)\n",
      "*   [Multi-Dataset Training](https://huggingface.co/blog/train-sentence-transformers#multi-dataset-training)\n",
      "*   [Deprecation](https://huggingface.co/blog/train-sentence-transformers#deprecation)\n",
      "*   [Additional Resources](https://huggingface.co/blog/train-sentence-transformers#additional-resources)\n",
      "    *   [Training Examples](https://huggingface.co/blog/train-sentence-transformers#training-examples)\n",
      "    *   [Documentation](https://huggingface.co/blog/train-sentence-transformers#documentation)\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#why-finetune)Why Finetune?\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Finetuning Sentence Transformer models can significantly enhance their performance on specific tasks. This is because each task requires a unique notion of similarity. Let's consider a couple of news article headlines as an example:\n",
      "\n",
      "*   \"Apple launches the new iPad\"\n",
      "*   \"NVIDIA is gearing up for the next GPU generation\"\n",
      "\n",
      "Depending on the use case, we might want similar or dissimilar embeddings for these texts. For instance, a classification model for news articles could treat these texts as similar since they both belong to the Technology category. On the other hand, a semantic textual similarity or retrieval model should consider them dissimilar due to their distinct meanings.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#training-components)Training Components\n",
      "--------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training Sentence Transformer models involves the following components:\n",
      "\n",
      "1.  [**Dataset**](https://huggingface.co/blog/train-sentence-transformers#dataset): The data used for training and evaluation.\n",
      "2.  [**Loss Function**](https://huggingface.co/blog/train-sentence-transformers#loss-function): A function that quantifies the model's performance and guides the optimization process.\n",
      "3.  [**Training Arguments**](https://huggingface.co/blog/train-sentence-transformers#training-arguments) (optional): Parameters that influence training performance and tracking/debugging.\n",
      "4.  [**Evaluator**](https://huggingface.co/blog/train-sentence-transformers#evaluator) (optional): A tool for evaluating the model before, during, or after training.\n",
      "5.  [**Trainer**](https://huggingface.co/blog/train-sentence-transformers#trainer): Brings together the model, dataset, loss function, and other components for training.\n",
      "\n",
      "Now, let's dive into each of these components in more detail.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#dataset)Dataset\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "The [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer) uses [`datasets.Dataset`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset) or [`datasets.DatasetDict`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict) instances for training and evaluation. You can load data from the Hugging Face Datasets Hub or use local data in various formats such as CSV, JSON, Parquet, Arrow, or SQL.\n",
      "\n",
      "Note: Many Hugging Face datasets that work out of the box with Sentence Transformers have been tagged with `sentence-transformers`, allowing you to easily find them by browsing to [https://huggingface.co/datasets?other=sentence-transformers](https://huggingface.co/datasets?other=sentence-transformers). We strongly recommend that you browse these datasets to find training datasets that might be useful for your tasks.\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#data-on-hugging-face-hub)Data on Hugging Face Hub\n",
      "\n",
      "To load data from datasets in the Hugging Face Hub, use the [`load_dataset`](https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset) function:\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "\n",
      "train_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"train\")\n",
      "eval_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"dev\")\n",
      "\n",
      "print(train_dataset)\n",
      "\"\"\"\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'label'],\n",
      "    num_rows: 942069\n",
      "})\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "Some datasets, like [`sentence-transformers/all-nli`](https://huggingface.co/datasets/sentence-transformers/all-nli), have multiple subsets with different data formats. You need to specify the subset name along with the dataset name.\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#local-data-csv-json-parquet-arrow-sql)Local Data (CSV, JSON, Parquet, Arrow, SQL)\n",
      "\n",
      "If you have local data in common file formats, you can easily load it using [`load_dataset`](https://huggingface.co/docs/datasets/main/en/package_reference/loading_methods#datasets.load_dataset) too:\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "\n",
      "dataset = load_dataset(\"csv\", data_files=\"my_file.csv\")\n",
      "# or\n",
      "dataset = load_dataset(\"json\", data_files=\"my_file.json\")\n",
      "```\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#local-data-that-requires-pre-processing)Local Data that requires pre-processing\n",
      "\n",
      "If your local data requires pre-processing, you can use [`datasets.Dataset.from_dict`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_dict) to initialize your dataset with a dictionary of lists:\n",
      "\n",
      "```\n",
      "from datasets import Dataset\n",
      "\n",
      "anchors = []\n",
      "positives = []\n",
      "# Open a file, perform preprocessing, filtering, cleaning, etc.\n",
      "# and append to the lists\n",
      "\n",
      "dataset = Dataset.from_dict({\n",
      "    \"anchor\": anchors,\n",
      "    \"positive\": positives,\n",
      "})\n",
      "```\n",
      "\n",
      "Each key in the dictionary becomes a column in the resulting dataset.\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#dataset-format)Dataset Format\n",
      "\n",
      "It's crucial to ensure that your dataset format matches your chosen [loss function](https://huggingface.co/blog/train-sentence-transformers#loss-function). This involves checking two things:\n",
      "\n",
      "1.  If your loss function requires a _Label_ (as indicated in the [Loss Overview](https://sbert.net/docs/sentence_transformer/loss_overview.html) table), your dataset must have a column named **\"label\"** or **\"score\"**.\n",
      "2.  All columns other than **\"label\"** or **\"score\"** are considered _Inputs_ (as indicated in the [Loss Overview](https://sbert.net/docs/sentence_transformer/loss_overview.html) table). The number of these columns must match the number of valid inputs for your chosen loss function. The names of the columns don't matter, **only their order matters**.\n",
      "\n",
      "For example, if your loss function accepts `(anchor, positive, negative) triplets`, then your first, second, and third dataset columns correspond with `anchor`, `positive`, and `negative`, respectively. This means that your first and second column must contain texts that should embed closely, and that your first and third column must contain texts that should embed far apart. That is why depending on your loss function, your dataset column order matters.\n",
      "\n",
      "Consider a dataset with columns `[\"text1\", \"text2\", \"label\"]`, where the `\"label\"` column contains floating point similarity scores. This dataset can be used with `CoSENTLoss`, `AnglELoss`, and `CosineSimilarityLoss` because:\n",
      "\n",
      "1.  The dataset has a \"label\" column, which is required by these loss functions.\n",
      "2.  The dataset has 2 non-label columns, matching the number of inputs required by these loss functions.\n",
      "\n",
      "If the columns in your dataset are not ordered correctly, use [`Dataset.select_columns`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.select_columns) to reorder them. Additionally, remove any extraneous columns (e.g., `sample_id`, `metadata`, `source`, `type`) using [`Dataset.remove_columns`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.remove_columns), as they will be treated as inputs otherwise.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#loss-function)Loss Function\n",
      "--------------------------------------------------------------------------------------\n",
      "\n",
      "Loss functions measure how well a model performs on a given batch of data and guide the optimization process. The choice of loss function depends on your available data and target task. Refer to the [Loss Overview](https://sbert.net/docs/sentence_transformer/loss_overview.html) for a comprehensive list of options.\n",
      "\n",
      "Most loss functions can be initialized with just the `SentenceTransformer` `model` that you're training:\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from sentence_transformers.losses import CoSENTLoss\n",
      "\n",
      "# Load a model to train/finetune\n",
      "model = SentenceTransformer(\"FacebookAI/xlm-roberta-base\")\n",
      "\n",
      "# Initialize the CoSENTLoss\n",
      "# This loss requires pairs of text and a floating point similarity score as a label\n",
      "loss = CoSENTLoss(model)\n",
      "\n",
      "# Load an example training dataset that works with our loss function:\n",
      "train_dataset = load_dataset(\"sentence-transformers/all-nli\", \"pair-score\", split=\"train\")\n",
      "\"\"\"\n",
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 942069\n",
      "})\n",
      "\"\"\"\n",
      "```\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#training-arguments)Training Arguments\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "The [`SentenceTransformersTrainingArguments`](https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments) class allows you to specify parameters that influence training performance and tracking/debugging. While optional, experimenting with these arguments can help improve training efficiency and provide insights into the training process.\n",
      "\n",
      "In the Sentence Transformers documentation, I've outlined some of the most useful training arguments. I would recommend reading it in [Training Overview > Training Arguments](https://sbert.net/docs/sentence_transformer/training_overview.html#training-arguments).\n",
      "\n",
      "Here's an example of how to initialize [`SentenceTransformersTrainingArguments`](https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments):\n",
      "\n",
      "```\n",
      "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
      "\n",
      "args = SentenceTransformerTrainingArguments(\n",
      "    # Required parameter:\n",
      "    output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
      "    # Optional training parameters:\n",
      "    num_train_epochs=1,\n",
      "    per_device_train_batch_size=16,\n",
      "    per_device_eval_batch_size=16,\n",
      "    warmup_ratio=0.1,\n",
      "    fp16=True,  # Set to False if your GPU can't handle FP16\n",
      "    bf16=False,  # Set to True if your GPU supports BF16\n",
      "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # Losses using \"in-batch negatives\" benefit from no duplicates\n",
      "    # Optional tracking/debugging parameters:\n",
      "    eval_strategy=\"steps\",\n",
      "    eval_steps=100,\n",
      "    save_strategy=\"steps\",\n",
      "    save_steps=100,\n",
      "    save_total_limit=2,\n",
      "    logging_steps=100,\n",
      "    run_name=\"mpnet-base-all-nli-triplet\",  # Used in W&B if `wandb` is installed\n",
      ")\n",
      "```\n",
      "\n",
      "Note that `eval_strategy` was introduced in `transformers` version `4.41.0`. Prior versions should use `evaluation_strategy` instead.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#evaluator)Evaluator\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "You can provide the [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer) with an `eval_dataset` to get the evaluation loss during training, but it may be useful to get more concrete metrics during training, too. For this, you can use evaluators to assess the model's performance with useful metrics before, during, or after training. You can both an `eval_dataset` and an evaluator, one or the other, or neither. They evaluate based on the `eval_strategy` and `eval_steps` [Training Arguments](https://huggingface.co/blog/train-sentence-transformers#training-arguments).\n",
      "\n",
      "Here are the implemented Evaluators that come with Sentence Tranformers:\n",
      "\n",
      "Additionally, you can use [`SequentialEvaluator`](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#sequentialevaluator) to combine multiple evaluators into one, which can then be passed to the [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer).\n",
      "\n",
      "If you don't have the necessary evaluation data but still want to track the model's performance on common benchmarks, you can use these evaluators with data from Hugging Face:\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#embeddingsimilarityevaluator-with-stsb)EmbeddingSimilarityEvaluator with STSb\n",
      "\n",
      "The STS Benchmark (a.k.a. STSb) is a commonly used benchmarking dataset to measure the model's understanding of semantic textual similarity of short texts like \"A man is feeding a mouse to a snake.\".\n",
      "\n",
      "Feel free to browse the [sentence-transformers/stsb](https://huggingface.co/datasets/sentence-transformers/stsb) dataset on Hugging Face.\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
      "\n",
      "# Load the STSB dataset\n",
      "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
      "\n",
      "# Initialize the evaluator\n",
      "dev_evaluator = EmbeddingSimilarityEvaluator(\n",
      "    sentences1=eval_dataset[\"sentence1\"],\n",
      "    sentences2=eval_dataset[\"sentence2\"],\n",
      "    scores=eval_dataset[\"score\"],\n",
      "    main_similarity=SimilarityFunction.COSINE,\n",
      "    name=\"sts-dev\",\n",
      ")\n",
      "# Run evaluation manually:\n",
      "# print(dev_evaluator(model))\n",
      "\n",
      "# Later, you can provide this evaluator to the trainer to get results during training\n",
      "```\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#tripletevaluator-with-allnli)TripletEvaluator with AllNLI\n",
      "\n",
      "AllNLI is a concatenation of the [SNLI](https://huggingface.co/datasets/stanfordnlp/snli) and [MultiNLI](https://huggingface.co/datasets/nyu-mll/multi_nli) datasets, both of which are datasets for Natural Language Inference. This task is traditionally for determining whether two texts are an entailment, contradiction, or neither. It has since been adopted for training embedding models, as the entailing and contradictory sentences make for useful `(anchor, positive, negative)` triplets: a common format for training embedding models.\n",
      "\n",
      "In this snippet, it is used to evaluate how frequently the model considers the anchor text and the entailing text to be more similar than the anchor text and the contradictory text. An example text is \"An older man is drinking orange juice at a restaurant.\".\n",
      "\n",
      "Feel free to browse the [sentence-transformers/all-nli](https://huggingface.co/datasets/sentence-transformers/all-nli) dataset on Hugging Face.\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "from sentence_transformers.evaluation import TripletEvaluator, SimilarityFunction\n",
      "\n",
      "# Load triplets from the AllNLI dataset\n",
      "max_samples = 1000\n",
      "eval_dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=f\"dev[:{max_samples}]\")\n",
      "\n",
      "# Initialize the evaluator\n",
      "dev_evaluator = TripletEvaluator(\n",
      "    anchors=eval_dataset[\"anchor\"],\n",
      "    positives=eval_dataset[\"positive\"],\n",
      "    negatives=eval_dataset[\"negative\"],\n",
      "    main_distance_function=SimilarityFunction.COSINE,\n",
      "    name=f\"all-nli-{max_samples}-dev\",\n",
      ")\n",
      "# Run evaluation manually:\n",
      "# print(dev_evaluator(model))\n",
      "\n",
      "# Later, you can provide this evaluator to the trainer to get results during training\n",
      "```\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#trainer)Trainer\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "The [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer) brings together the model, dataset, loss function, and other components for training:\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "from sentence_transformers import (\n",
      "    SentenceTransformer,\n",
      "    SentenceTransformerTrainer,\n",
      "    SentenceTransformerTrainingArguments,\n",
      "    SentenceTransformerModelCardData,\n",
      ")\n",
      "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
      "from sentence_transformers.training_args import BatchSamplers\n",
      "from sentence_transformers.evaluation import TripletEvaluator\n",
      "\n",
      "# 1. Load a model to finetune with 2. (Optional) model card data\n",
      "model = SentenceTransformer(\n",
      "    \"microsoft/mpnet-base\",\n",
      "    model_card_data=SentenceTransformerModelCardData(\n",
      "        language=\"en\",\n",
      "        license=\"apache-2.0\",\n",
      "        model_name=\"MPNet base trained on AllNLI triplets\",\n",
      "    )\n",
      ")\n",
      "\n",
      "# 3. Load a dataset to finetune on\n",
      "dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\")\n",
      "train_dataset = dataset[\"train\"].select(range(100_000))\n",
      "eval_dataset = dataset[\"dev\"]\n",
      "test_dataset = dataset[\"test\"]\n",
      "\n",
      "# 4. Define a loss function\n",
      "loss = MultipleNegativesRankingLoss(model)\n",
      "\n",
      "# 5. (Optional) Specify training arguments\n",
      "args = SentenceTransformerTrainingArguments(\n",
      "    # Required parameter:\n",
      "    output_dir=\"models/mpnet-base-all-nli-triplet\",\n",
      "    # Optional training parameters:\n",
      "    num_train_epochs=1,\n",
      "    per_device_train_batch_size=16,\n",
      "    per_device_eval_batch_size=16,\n",
      "    warmup_ratio=0.1,\n",
      "    fp16=True,  # Set to False if GPU can't handle FP16\n",
      "    bf16=False,  # Set to True if GPU supports BF16\n",
      "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicates\n",
      "    # Optional tracking/debugging parameters:\n",
      "    eval_strategy=\"steps\",\n",
      "    eval_steps=100,\n",
      "    save_strategy=\"steps\",\n",
      "    save_steps=100,\n",
      "    save_total_limit=2,\n",
      "    logging_steps=100,\n",
      "    run_name=\"mpnet-base-all-nli-triplet\",  # Used in W&B if `wandb` is installed\n",
      ")\n",
      "\n",
      "# 6. (Optional) Create an evaluator & evaluate the base model\n",
      "dev_evaluator = TripletEvaluator(\n",
      "    anchors=eval_dataset[\"anchor\"],\n",
      "    positives=eval_dataset[\"positive\"],\n",
      "    negatives=eval_dataset[\"negative\"],\n",
      "    name=\"all-nli-dev\",\n",
      ")\n",
      "dev_evaluator(model)\n",
      "\n",
      "# 7. Create a trainer & train\n",
      "trainer = SentenceTransformerTrainer(\n",
      "    model=model,\n",
      "    args=args,\n",
      "    train_dataset=train_dataset,\n",
      "    eval_dataset=eval_dataset,\n",
      "    loss=loss,\n",
      "    evaluator=dev_evaluator,\n",
      ")\n",
      "trainer.train()\n",
      "\n",
      "# (Optional) Evaluate the trained model on the test set, after training completes\n",
      "test_evaluator = TripletEvaluator(\n",
      "    anchors=test_dataset[\"anchor\"],\n",
      "    positives=test_dataset[\"positive\"],\n",
      "    negatives=test_dataset[\"negative\"],\n",
      "    name=\"all-nli-test\",\n",
      ")\n",
      "test_evaluator(model)\n",
      "\n",
      "# 8. Save the trained model\n",
      "model.save_pretrained(\"models/mpnet-base-all-nli-triplet/final\")\n",
      "\n",
      "# 9. (Optional) Push it to the Hugging Face Hub\n",
      "model.push_to_hub(\"mpnet-base-all-nli-triplet\")\n",
      "```\n",
      "\n",
      "In this example I'm finetuning from [`microsoft/mpnet-base`](https://huggingface.co/microsoft/mpnet-base), a base model that is not yet a Sentence Transformer model. This requires more training data than finetuning an existing Sentence Transformer model, like [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2).\n",
      "\n",
      "After running this script, the [tomaarsen/mpnet-base-all-nli-triplet](https://huggingface.co/tomaarsen/mpnet-base-all-nli-triplet) model was uploaded for me. The triplet accuracy using cosine similarity, i.e. what percentage of the time `cosine_similarity(anchor, positive) > cosine_similarity(anchor, negative)` is 90.04% for the development set and 91.5% for the testing set! For reference, the [`microsoft/mpnet-base`](https://huggingface.co/microsoft/mpnet-base) model scored only 68.32% on the dev set before training.\n",
      "\n",
      "All of this information is stored in the automatically generated model card, including the base model, language, license, evaluation results, training & evaluation dataset info, hyperparameters, training logs, and more. Without any effort, your uploaded models should contain all the information that your potential users would need to determine whether your model is suitable for them.\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#callbacks)Callbacks\n",
      "\n",
      "The Sentence Transformers trainer supports various [`transformers.TrainerCallback`](https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback) subclasses, including:\n",
      "\n",
      "*   [`WandbCallback`](https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.WandbCallback) for logging training metrics to W&B if `wandb` is installed\n",
      "*   [`TensorBoardCallback`](https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.TensorBoardCallback) for logging training metrics to TensorBoard if `tensorboard` is accessible\n",
      "*   [`CodeCarbonCallback`](https://huggingface.co/docs/transformers/en/main_classes/callback#transformers.integrations.CodeCarbonCallback) for tracking carbon emissions during training if `codecarbon` is installed\n",
      "\n",
      "These are automatically used without you having to specify anything, as long as the required dependency is installed.\n",
      "\n",
      "Refer to the [Transformers Callbacks documentation](https://huggingface.co/docs/transformers/en/main_classes/callback) for more information on these callbacks and how to create your own.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#multi-dataset-training)Multi-Dataset Training\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Top-performing models are often trained using multiple datasets simultaneously. The [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer) simplifies this process by allowing you to train with multiple datasets without converting them to the same format. You can even apply different loss functions to each dataset. Here are the steps for multi-dataset training:\n",
      "\n",
      "1.  Use a dictionary of [`datasets.Dataset`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset) instances (or a [`datasets.DatasetDict`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.DatasetDict)) as the `train_dataset` and `eval_dataset`.\n",
      "2.  (Optional) Use a dictionary of loss functions mapping dataset names to losses if you want to use different losses for different datasets.\n",
      "\n",
      "Each training/evaluation batch will contain samples from only one of the datasets. The order in which batches are sampled from the multiple datasets is determined by the [`MultiDatasetBatchSamplers`](https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentence_transformers.training_args.MultiDatasetBatchSamplers) enum, which can be passed to the [`SentenceTransformersTrainingArguments`](https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#sentencetransformertrainingarguments) via `multi_dataset_batch_sampler`. The valid options are:\n",
      "\n",
      "*   `MultiDatasetBatchSamplers.ROUND_ROBIN`: Samples from each dataset in a round-robin fashion until one is exhausted. This strategy may not use all samples from each dataset, but it ensures equal sampling from each dataset.\n",
      "*   `MultiDatasetBatchSamplers.PROPORTIONAL` (default): Samples from each dataset proportionally to its size. This strategy ensures that all samples from each dataset are used, and larger datasets are sampled from more frequently.\n",
      "\n",
      "Multi-task training has proven to be highly effective. For instance, [Huang et al. 2024](https://arxiv.org/pdf/2405.06932) employed [`MultipleNegativesRankingLoss`](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss), [`CoSENTLoss`](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cosentloss), and a variation of [`MultipleNegativesRankingLoss`](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss) without in-batch negatives and only hard negatives to achieve state-of-the-art performance on Chinese. They also applied [`MatryoshkaLoss`](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#matryoshkaloss) to enable the model to produce [Matryoshka Embeddings](https://huggingface.co/blog/matryoshka).\n",
      "\n",
      "Here's an example of multi-dataset training:\n",
      "\n",
      "```\n",
      "from datasets import load_dataset\n",
      "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer\n",
      "from sentence_transformers.losses import CoSENTLoss, MultipleNegativesRankingLoss, SoftmaxLoss\n",
      "\n",
      "# 1. Load a model to finetune\n",
      "model = SentenceTransformer(\"bert-base-uncased\")\n",
      "\n",
      "# 2. Loadseveral Datasets to train with\n",
      "# (anchor, positive)\n",
      "all_nli_pair_train = load_dataset(\"sentence-transformers/all-nli\", \"pair\", split=\"train[:10000]\")\n",
      "# (premise, hypothesis) + label\n",
      "all_nli_pair_class_train = load_dataset(\"sentence-transformers/all-nli\", \"pair-class\", split=\"train[:10000]\")\n",
      "# (sentence1, sentence2) + score\n",
      "all_nli_pair_score_train = load_dataset(\"sentence-transformers/all-nli\", \"pair-score\", split=\"train[:10000]\")\n",
      "# (anchor, positive, negative)\n",
      "all_nli_triplet_train = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"train[:10000]\")\n",
      "# (sentence1, sentence2) + score\n",
      "stsb_pair_score_train = load_dataset(\"sentence-transformers/stsb\", split=\"train[:10000]\")\n",
      "# (anchor, positive)\n",
      "quora_pair_train = load_dataset(\"sentence-transformers/quora-duplicates\", \"pair\", split=\"train[:10000]\")\n",
      "# (query, answer)\n",
      "natural_questions_train = load_dataset(\"sentence-transformers/natural-questions\", split=\"train[:10000]\")\n",
      "\n",
      "# Combine all datasets into a dictionary with dataset names to datasets\n",
      "train_dataset = {\n",
      "    \"all-nli-pair\": all_nli_pair_train,\n",
      "    \"all-nli-pair-class\": all_nli_pair_class_train,\n",
      "    \"all-nli-pair-score\": all_nli_pair_score_train,\n",
      "    \"all-nli-triplet\": all_nli_triplet_train,\n",
      "    \"stsb\": stsb_pair_score_train,\n",
      "    \"quora\": quora_pair_train,\n",
      "    \"natural-questions\": natural_questions_train,\n",
      "}\n",
      "\n",
      "# 3. Load several Datasets to evaluate with\n",
      "# (anchor, positive, negative)\n",
      "all_nli_triplet_dev = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"dev\")\n",
      "# (sentence1, sentence2, score)\n",
      "stsb_pair_score_dev = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
      "# (anchor, positive)\n",
      "quora_pair_dev = load_dataset(\"sentence-transformers/quora-duplicates\", \"pair\", split=\"train[10000:11000]\")\n",
      "# (query, answer)\n",
      "natural_questions_dev = load_dataset(\"sentence-transformers/natural-questions\", split=\"train[10000:11000]\")\n",
      "\n",
      "# Use a dictionary for the evaluation dataset too, or just use one dataset or none at all\n",
      "eval_dataset = {\n",
      "    \"all-nli-triplet\": all_nli_triplet_dev,\n",
      "    \"stsb\": stsb_pair_score_dev,\n",
      "    \"quora\": quora_pair_dev,\n",
      "    \"natural-questions\": natural_questions_dev,\n",
      "}\n",
      "\n",
      "# 4. Load several loss functions to train with\n",
      "# (anchor, positive), (anchor, positive, negative)\n",
      "mnrl_loss = MultipleNegativesRankingLoss(model)\n",
      "# (sentence_A, sentence_B) + class\n",
      "softmax_loss = SoftmaxLoss(model)\n",
      "# (sentence_A, sentence_B) + score\n",
      "cosent_loss = CoSENTLoss(model)\n",
      "\n",
      "# Create a mapping with dataset names to loss functions, so the trainer knows which loss to apply where\n",
      "# Note: You can also just use one loss if all your training/evaluation datasets use the same loss\n",
      "losses = {\n",
      "    \"all-nli-pair\": mnrl_loss,\n",
      "    \"all-nli-pair-class\": softmax_loss,\n",
      "    \"all-nli-pair-score\": cosent_loss,\n",
      "    \"all-nli-triplet\": mnrl_loss,\n",
      "    \"stsb\": cosent_loss,\n",
      "    \"quora\": mnrl_loss,\n",
      "    \"natural-questions\": mnrl_loss,\n",
      "}\n",
      "\n",
      "# 5. Define a simple trainer, although it's recommended to use one with args & evaluators\n",
      "trainer = SentenceTransformerTrainer(\n",
      "    model=model,\n",
      "    train_dataset=train_dataset,\n",
      "    eval_dataset=eval_dataset,\n",
      "    loss=losses,\n",
      ")\n",
      "trainer.train()\n",
      "\n",
      "# 6. Save the trained model and optionally push it to the Hugging Face Hub\n",
      "model.save_pretrained(\"bert-base-all-nli-stsb-quora-nq\")\n",
      "model.push_to_hub(\"bert-base-all-nli-stsb-quora-nq\")\n",
      "```\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#deprecation)Deprecation\n",
      "----------------------------------------------------------------------------------\n",
      "\n",
      "Prior to the Sentence Transformer v3 release, all models would be trained using the [`SentenceTransformer.fit`](https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.fit) method. Rather than deprecating this method, starting from v3.0, this method will use the [`SentenceTransformerTrainer`](https://sbert.net/docs/package_reference/sentence_transformer/trainer.html#sentence_transformers.trainer.SentenceTransformerTrainer) behind the scenes. This means that your old training code should still work, and should even be upgraded with the new features such as multi-gpu training, loss logging, etc. That said, the new training approach is much more powerful, so it is **recommended** to write new training scripts using the new approach.\n",
      "\n",
      "[](https://huggingface.co/blog/train-sentence-transformers#additional-resources)Additional Resources\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#training-examples)Training Examples\n",
      "\n",
      "The following pages contain training examples with explanations as well as links to code. We recommend that you browse through these to familiarize yourself with the training loop:\n",
      "\n",
      "*   [Semantic Textual Similarity](https://sbert.net/examples/training/sts/README.html)\n",
      "*   [Natural Language Inference](https://sbert.net/examples/training/nli/README.html)\n",
      "*   [Paraphrases](https://sbert.net/examples/training/paraphrases/README.html)\n",
      "*   [Quora Duplicate Questions](https://sbert.net/examples/training/quora_duplicate_questions/README.html)\n",
      "*   [Matryoshka Embeddings](https://sbert.net/examples/training/matryoshka/README.html)\n",
      "*   [Adaptive Layer Models](https://sbert.net/examples/training/adaptive_layer/README.html)\n",
      "*   [Multilingual Models](https://sbert.net/examples/training/multilingual/README.html)\n",
      "*   [Model Distillation](https://sbert.net/examples/training/distillation/README.html)\n",
      "*   [Augmented Sentence Transformers](https://sbert.net/examples/training/data_augmentation/README.html)\n",
      "\n",
      "### [](https://huggingface.co/blog/train-sentence-transformers#documentation)Documentation\n",
      "\n",
      "Additionally, the following pages may be useful to learn more about Sentence Transformers:\n",
      "\n",
      "*   [Installation](https://sbert.net/docs/installation.html)\n",
      "*   [Quickstart](https://sbert.net/docs/quickstart.html)\n",
      "*   [Usage](https://sbert.net/docs/sentence_transformer/usage/usage.html)\n",
      "*   [Pretrained Models](https://sbert.net/docs/sentence_transformer/pretrained_models.html)\n",
      "*   [Training Overview](https://sbert.net/docs/sentence_transformer/training_overview.html) (This blogpost is a distillation of the Training Overiew documentation)\n",
      "*   [Dataset Overview](https://sbert.net/docs/sentence_transformer/dataset_overview.html)\n",
      "*   [Loss Overview](https://sbert.net/docs/sentence_transformer/loss_overview.html)\n",
      "*   [API Reference](https://sbert.net/docs/package_reference/sentence_transformer/index.html)\n",
      "\n",
      "And lastly, here are some advanced pages that might interest you:\n",
      "\n",
      "*   [Hyperparameter Optimization](https://sbert.net/examples/training/hpo/README.html)\n",
      "*   [Distributed Training](https://sbert.net/docs/sentence_transformer/training/distributed.html)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdata = jinaai_readerapi_web_scrape_url(url)\n",
    "print(jdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents\n",
      "\n",
      "URL Source: https://arxiv.org/pdf/2310.19923v4\n",
      "\n",
      "Markdown Content:\n",
      "# JINA EMBEDDINGS 2: 8192 -Token General-Purpose Text Embeddings for Long Documents \n",
      "\n",
      "## Michael Günther, Jackmin Ong, Isabelle Mohr, Alaeddine Abdessalem, Tanguy Abel, Mohammad Kalim Akram , Susana Guzman , Georgios Mastrapas , Saba Sturua ,\n",
      "\n",
      "## Bo Wang , Maximilian Werk , Nan Wang and Han Xiao \n",
      "\n",
      "## Jina AI GmbH, Ohlauer Str. 43, 10999 Berlin, Germany \n",
      "\n",
      "## {michael.guenther, jackmin.ong, isabelle.mohr alaeddine.abdessalem, tanguy.abel, kalim.akram, susana.guzman, georgios.mastrapas, saba.sturua, bo.wang, maximilian.werk, nan.wang, han.xiao}@jina.ai \n",
      "\n",
      "## Abstract \n",
      "\n",
      "Text embedding models have emerged as pow-erful tools for transforming sentences into fixed-sized feature vectors that encapsulate seman-tic information. While these models are es-sential for tasks like information retrieval, se-mantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to miti-gate this challenge involves splitting documents into smaller paragraphs for embedding. How-ever, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally in-tensive vector searches with elevated latency. To address these challenges, we intro-duce Jina Embeddings v2 , an open-source text embedding model 1 capable of ac-commodating up to 8192 tokens. This model is designed to transcend the conven-tional 512 -token limit and adeptly process long documents. Jina Embeddings v2 not only achieves state-of-the-art performance on a range of embedding-related tasks in the MTEB benchmark but also matches the performance of OpenAI’s proprietary \n",
      "\n",
      "text-embedding-ada-002 model. Addition-ally, our experiments indicate that an extended context can enhance performance in tasks such as NarrativeQA. \n",
      "\n",
      "## 1 Introduction \n",
      "\n",
      "Using neural networks to encode text and images into embedding representations has become a stan-dard practice for analyzing and processing vast amounts of unstructured data. In natural language processing, sentence embedding models [Reimers      \n",
      "\n",
      "> 1Base model (0.27G): https://huggingface.co/ jinaai/jina-embeddings-v2-base-en\n",
      "> Small model (0.07G): https://huggingface.co/jinaai/ jina-embeddings-v2-small-en\n",
      "> API: https://jina.ai/embeddings\n",
      "\n",
      "and Gurevych, 2019] transform the semantics of phrases, sentences, and paragraphs into points within a continuous vector space. These trans-formed data points can subsequently be used for a myriad of downstream applications, such as infor-mation retrieval, as well as clustering and classifi-cation tasks. Despite the numerous applications of embed-ding models, a prevailing challenge faced by many models is the limitation on the maximum sequence lengths of text that can be encoded into a single embedding. To circumvent this, practitioners of-ten segment documents into smaller chunks prior to encoding. This tactic, unfortunately, results in fragmented semantic meanings, causing the em-beddings to misrepresent the entirety of paragraphs. Furthermore, this method yields a plethora of vec-tors, culminating in heightened memory usage, increased computational demands during vector searches, and extended latencies. The dilemma is exacerbated when embedding vectors are stored in database systems that construct memory-intensive index structures. The root of these text length restrictions can be traced back to the BERT architecture, which un-derpins most of the current open-source models. The authors of [Press et al., 2022] demonstrated that these models struggle to accurately represent long documents. They introduced an alternative positional embedding method named ALiBi, en-abling efficient training of models to encode long text sequences. Regrettably, up until this point, the approach was exclusively employed for gen-erative language models, neglecting its potential for open-source encoder language models aimed at crafting document embeddings. This research bridges that gap by incorporating ALiBi bidirec-tionally into the BERT framework, rendering it apt for encoding tasks. As a result, it empowers users to utilize it for downstream operations on texts spanning up to 8192 tokens. Moreover, we \n",
      "\n",
      "> arXiv:2310.19923v4 [cs.CL] 4 Feb 2024\n",
      "\n",
      "fine-tuned this enhanced BERT model, harness-ing hundreds of millions of text samples to en-code texts into singular embedding representations. Our model’s resultant embeddings outshine those of the Jina Embeddings v1 model suite [Günther et al., 2023] in the MTEB benchmark and rival the prowess of state-of-the-art models like E5 [Wang et al., 2022]. We also found that large context lengths can amplify the efficacy of numerous down-stream tasks tied to embeddings. Given that the ma-jority of available embedding evaluation datasets comprise mainly brief text passages, we have cu-rated datasets encompassing long text values to bet-ter evaluate embeddings. These datasets, alongside our models, are made accessible via our Hugging Face repository 2.This paper is structured as follows: We begin with an overview of related work in Section 2. This is followed by an outline of the training paradigm in Section 3, a description of the backbone model and its pre-training in Section 4, and a detailed walkthrough of the fine-tuning process for embed-dings generation in Section 5. We culminate with an exhaustive evaluation in Section 6 and conclu-sions in Section 7. \n",
      "\n",
      "## 2 Related Work \n",
      "\n",
      "Embedding training has undergone significant evo-lution, transitioning from foundational techniques such as Latent Semantic Indexing (LSA) [Deer-wester et al., 1990] and Latent Dirichlet Alloca-tion (LDA) [Blei et al., 2001] to the sophisticated prowess of pre-trained models like Sentence-BERT [Reimers and Gurevych, 2019]. A notable shift in recent advancements is the emphasis on unsuper-vised contrastive learning, as showcased by works like [Gao et al., 2022, Wang et al., 2022]. Pio-neering models like Condenser [Gao and Callan, 2021] and RetroMAE [Xiao et al., 2022] have brought forth specialized architectures and pre-training methods explicitly designed for dense en-coding and retrieval. The E5 [Wang et al., 2022], \n",
      "\n",
      "Jina Embeddings v1 [Günther et al., 2023], and GTE [Li et al., 2023] collections of em-bedding models represent another leap forward. These models propose a holistic framework tailored for effective training across a myriad of tasks. This framework adopts a multi-stage contrastive training approach. An initial phase \n",
      "\n",
      "> 2https://huggingface.co/jinaai\n",
      "\n",
      "focuses on training using a vast collection of weak pairs sourced from public data, enhancing the model’s domain generalization. Following this, a supervised fine-tuning stage employs a curated set of annotated text triples, representing diverse tasks. Together, these sequential stages yield state-of-the-art outcomes on the MTEB benchmark. Yet, despite such advancements, a glaring lim-itation persists: the 512 -token constraint on input sequences, stemming from foundational models like BERT. This cap is insufficient for encoding lengthy documents, often exceeding a page. AL-iBi [Press et al., 2022] emerges as a promising solu-tion, presenting a technique that sidesteps conven-tional positional embeddings and facilitates train-ing on sequences exceeding 2048 tokens. Notably, its typical application is centered around generative models, which inherently adopt a unidirectional bias, rendering it less suitable for embedding tasks. Effective evaluation remains paramount for em-bedding models, ensuring they meet the diverse demands of real-world applications. The BEIR benchmark [Thakur et al., 2021] stands out, offer-ing evaluations across a set of retrieval tasks and settings. Similarly, the MTEB benchmark [Muen-nighoff et al., 2023] highlights the extensive appli-cability of text embeddings, spanning a variety of tasks and languages. However, a notable gap in both benchmarks is their limited focus on encoding long documents — a critical aspect for comprehen-sive embedding evaluation. \n",
      "\n",
      "## 3 Training Paradigm Overview \n",
      "\n",
      "The training paradigm for Jina Embeddings v2 is divided into three stages: I Pre-training a Modified BERT: For the back-bone language model, we propose a modi-fied BERT model capable of encoding doc-uments with up to 8192 tokens. This model is trained from scratch on a full-text corpus using a masked language modeling objective. II Fine-tuning with Text Pairs: To encode a text passage into a single vector representa-tion, the model is fine-tuned on text pairs. III Fine-tuning with Hard Negatives: The model is further fine-tuned using text pairs complemented with hard negatives. This stage is crucial for enabling the model to better Model Layers Hidden Params \n",
      "\n",
      "Jina BERT Small 4 512 33M \n",
      "\n",
      "Jina BERT Base 12 768 137M \n",
      "\n",
      "Jina BERT Large 24 1024 455M         \n",
      "\n",
      "> Table 1: Architecture specifications for the\n",
      "> Jina BERT models of varying sizes. The number of attention heads is selected to ensure a consistent head dimension of 64 .\n",
      "\n",
      "distinguish between relevant passages and re-lated, but irrelevant text passages. While both stages II and III are geared towards training the models for embedding tasks, the latter is especially critical for improving the model’s per-formance in retrieval and classification tasks (refer to Section 6.2). \n",
      "\n",
      "## 4 Pre-training a Modified BERT \n",
      "\n",
      "For the backbone language model, we introduce a novel transformer based on BERT [Devlin et al., 2019] with several modifications to enhance its ability to encode extended text sequences and to generally bolster its language modeling capabili-ties. For the training process, we largely adopt the approach described in [Liu et al., 2019a], incorpo-rating additional performance optimizations. \n",
      "\n",
      "4.1 Model Architecture Attention with Linear Biases: For the self-attention mechanism within the attention blocks, we adopt the Attention with Linear Biases (AL-iBi) approach [Press et al., 2022]. ALiBi forgoes the use of positional embeddings. Instead, it en-codes positional information directly within the self-attention layer by introducing a constant bias term to the attention score matrix of each layer, en-suring that proximate tokens demonstrate stronger mutual attention. While the original implementa-tion was designed for causal language modeling and featured biases solely in the causal direction, such an approach is not compatible with the bidirec-tional self-attention inherent in our encoder model. For our purposes, we employ the symmetric en-coder variant where attention biases are mirrored to ensure consistency in both directions 3. Figure 1 depicts the computation of attention scores within the multi-head attention heads. Each head’s scaling \n",
      "\n",
      "> 3https://github.com/ofirpress/attention_with_ linear_biases/issues/5\n",
      "\n",
      "value, mi, out of the total n heads, is derived using Equation (1). \n",
      "\n",
      "mi =\n",
      "\n",
      "(\n",
      "\n",
      "b2i i < a b1+2( i−a) i ≥ aa = 2 ⌊log 2 n⌋ b = 2 −82⌈log 2 n⌉ (1) \n",
      "\n",
      "Gated Linear Units: For the feedforward sub-layers within the attention blocks, we adopt Gated Linear Units (GLU), originally introduced in [Dauphin et al., 2016]. They’ve demonstrated per-formance enhancements when incorporated into transformers [Shazeer, 2020]. For the small and base models, we employ the GEGLU variant, which leverages the GELU activation function for the GLU. Conversely, for the large model, we uti-lize the ReGLU variant with the ReLU activation function. This choice was driven by our observa-tion that training the large model with GEGLU, despite its promising initial MLM accuracy, was unstable. \n",
      "\n",
      "Layer Normalization: Regarding Layer Normal-ization [ ?], we align with the post-layer normaliza-tion approach from [Vaswani et al., 2017] in our at-tention blocks. Preliminary tests with pre-layer nor-malization, as mentioned in [Shoeybi et al., 2019] and [Nguyen and Salazar, 2019], didn’t enhance training stability or performance. Consequently, we opted not to integrate it into our model. \n",
      "\n",
      "4.2 Training Data \n",
      "\n",
      "For the pre-training phase, we leverage the English “Colossal, Cleaned, Common Crawl (C4)” dataset 4,encompassing approximately 365 million text docu-ments harvested from the web, summing to around 170 billion tokens. As delineated in [Raffel et al., 2020], the C4 dataset is a refined iteration of Com-mon Crawl, utilizing heuristics for cleanup and lan-guage recognition, retaining solely English content. As a result, our models are monolingual and tai-lored exclusively for English texts. The purification process also encompasses the removal of webpages hosting inappropriate content. We reserve 1% of the dataset for evaluating validation loss and the accuracy of the masked language modeling (MLM) task. \n",
      "\n",
      "> 4https://huggingface.co/datasets/c4\n",
      "\n",
      "(a) Encoder ALiBi (b) Causal ALiBi  \n",
      "\n",
      "> Figure 1: With ALiBi attention, a linear bias is incorporated into each attention score preceding the softmax operation. Each attention head employs a distinct constant scalar, m, which diversifies its computation. Our model adopts the encoder variant where all tokens mutually attend during calculation, contrasting the causal variant originally designed for language modeling. In the latter, a causal mask confines tokens to attend solely to preceding tokens in the sequence.\n",
      "\n",
      "4.3 Training Algorithm \n",
      "\n",
      "Our model’s pre-training revolves around the masked language modeling objective, excluding the next sentence prediction (NSP) task due to its perceived limited contribution to downstream task performance [Liu et al., 2019a]. We mask 30% \n",
      "\n",
      "of the input tokens randomly, employing whole word masking [Devlin et al., 2019], and condi-tion the models to infer these masked tokens. Of these masked tokens, 80% are substituted with the \n",
      "\n",
      "[MASK] token, 10% with a random token, and the remaining 10% stay unaltered. The masked tokens are predicted by a decoder \n",
      "\n",
      "f : Rd → R|V |, which takes the output token em-bedding ei ∈ Rd of a masked token and predicts a probability for each token in the vocabulary. The loss LMLM is computed by evaluating the cross entropy between the predicted probabilities and the actual masked tokens, as described in Equation (2) .Here, I : {1, . . . , n } → | V | denotes the function that maps each of the n masked tokens to its re-spective index in the vocabulary: \n",
      "\n",
      "LMLM (t) := \n",
      "\n",
      "> n\n",
      "\n",
      "X\n",
      "\n",
      "> k=1\n",
      "\n",
      "ln f (ei)I(k) (2) Given our model’s reliance on ALiBi atten-tion [Press et al., 2022], training position embed-dings becomes unnecessary. This allows us to pre-train more efficiently on shorter sequences and adapt to longer sequences in subsequent tasks. Throughout our pre-training, we operate on se-quences capped at 512 tokens in length. Diverg-ing from the methods in [Devlin et al., 2019] and [Liu et al., 2019a], our sequences originate from individual documents without any multi-document packing. Furthermore, we refrain from sampling multiple sequences from a singular document. For each document, we exclusively consider its initial 512 tokens, truncating any excess. Given our con-sistent global batch size of 4096, each batch, due to its varying sequence length, contains a unique number of masked tokens when calculating loss. \n",
      "\n",
      "Optimizer: Mirroring the optimization strategy of RoBERTa [Liu et al., 2019a], we employ the AdamW algorithm [Loshchilov and Hutter, 2017], characterized by parameters β1 = 0 .9, β2 = 0 .98 ,\n",
      "\n",
      "ϵ = 1e −6, a weight decay of 0.01 , dropout set at \n",
      "\n",
      "0.1, and attention dropout also at 0.1. Our learning rate schedule is linear, starting at 0 and peaking at a rate of η post 10 , 000 steps. Here, the values of \n",
      "\n",
      "η are designated as 1e −3, 6e −4, and 4e −4 for the small, base, and large models respectively. A linear decay to zero ensues after reaching the 100 , 000 \n",
      "\n",
      "steps threshold. \n",
      "\n",
      "Mixed precision training: We resort to FP16 dy-namic mixed precision [Micikevicius et al., 2018] for pre-training our models, facilitated by the Deep-Speed software package [Rasley et al., 2020]. Our preliminary tests using BF16 revealed unsatisfac-tory performance metrics, both in MLM accuracy and the downstream GLUE tasks. \n",
      "\n",
      "## 5 Fine-Tuning for Embeddings \n",
      "\n",
      "After pre-training the Jina BERT models, we fur-ther fine-tune each of the models to encode a text se-quence into a single vector representation. The core idea behind our embedding approach is inspired by the Sentence-BERT [Reimers and Gurevych, 2019]. To enable a model to perform a text oper-ation, we augment it with a mean pooling layer. This mean pooling step averages the token embed-dings to merge their information into a single repre-sentation, without introducing additional trainable parameters. The training process for this enhanced model consists of an unsupervised phase followed by a supervised one. \n",
      "\n",
      "5.1 Fine-tuning with Text Pairs \n",
      "\n",
      "During the first fine-tuning stage, we train the mod-els on a corpus of text pairs (q, p ) ∈ Dpairs , com-prising a query string q and a target string p.\n",
      "\n",
      "Training Data We utilize roughly 40 diverse data sources, akin to the data preparation outlined in the report we previously published about our inaugu-ral embedding model suite [Günther et al., 2023]. We observed that the inclusion of title-abstract pairs from documents significantly enhances per-formance on clustering tasks. As detailed in [Gün-ther et al., 2023], we implement consistency filter-ing [Dai et al., 2023, Wang et al., 2022] to elevate the quality of the text pair corpus. For batch cre-ation, we adhere to our earlier strategy: for every new batch, we randomly choose a data source and extract as many pairs as needed to fill that batch. All pairs within the data sources are pre-shuffled. Depending on the quality and quantity of the data sources, we assign different sampling rates for the pairs. \n",
      "\n",
      "Loss Function: The goal of this fine-tuning stage is to encode text values that constitute a pair into analogous embedding representations, while en-coding texts that aren’t paired into distinct embed-dings. To achieve this contrastive goal, we employ the InfoNCE [van den Oord et al., 2018] loss func-tion, similar to our earlier embedding models [Gün-ther et al., 2023]. This loss function calculates the loss value for a pair (q, p ) ∼ B within a batch \n",
      "\n",
      "B ⊂ Dpairs as follows: \n",
      "\n",
      "Lpairs NCE (B) := E(q,p )∼B\n",
      "\n",
      "− ln es(q,p )/τ kP\n",
      "\n",
      "> i=1\n",
      "\n",
      "es(q,p i)/τ \n",
      "\n",
      " (3) The function evaluates the cosine similarity \n",
      "\n",
      "s(p, q ) between a given query q and its correspond-ing target p, relative to the similarity of all other targets in the batch. Given the typically symmetric nature of similarity measures, we compute the loss in both directions: \n",
      "\n",
      "Lpairs (B) := Lpairs NCE (B) + Lpairs NCE (B), with \n",
      "\n",
      "Lpairs NCE (B) := E(q,p )∼B\n",
      "\n",
      "− ln es(p,q )/τ kP\n",
      "\n",
      "> i=1\n",
      "\n",
      "es(p,q i)/τ \n",
      "\n",
      " (4) The constant temperature parameter τ influences how the loss function weighs minor differences in the similarity scores [Wang and Liu, 2021]. Empir-ical testing suggests that τ = 0 .05 is effective. \n",
      "\n",
      "5.2 Fine-tuning with Hard Negatives \n",
      "\n",
      "The goal of the supervised fine-tuning stage is to improve the models’ ranking capabilities. This improvement is achieved by training with datasets that include additional negative examples. \n",
      "\n",
      "Training Data We have prepared retrieval datasets, such as MSMarco [Bajaj et al., 2016] and Natural Questions (NQ) [Kwiatkowski et al., 2019], in addition to multiple non-retrieval datasets like the Natural Language Inference (NLI) dataset [Bowman et al., 2015]. These datasets en-compass a collection of queries with annotated rel-evant passages and several negative examples, con-sistent with earlier work [Wang et al., 2022]. Each training batch B, structured as (q, p, n 1, . . . , n 15 ),includes one positive and 15 negative instances. For retrieval datasets, hard negatives are discerned by identifying passages deemed similar by retrieval models. This approach instructs the model to prior-itize relevant documents over those that are merely semantically related. For non-retrieval datasets, negatives are selected randomly, since drawing a clear line between positives and hard negatives isn’t feasible. This is because, unlike relevancy, it’s chal-lenging to make a binary determination regarding the similarity or dissimilarity of two textual values. Consequently, opting for hard negatives in such datasets seemed to diminish the models’ quality. Nonetheless, it remains crucial to integrate these datasets into the stage III training to ensure contin-ued performance on non-retrieval tasks. To ensure that hard negative passages are indeed less rele-vant than the annotated relevant ones, we employ a cross-encoder model to validate that their relevance score is indeed lower. \n",
      "\n",
      "Loss Function: Our training employs a modified variant of the InfoNCE loss function, denoted as \n",
      "\n",
      "LNCE + and described by Equation (5) . Similar to the preceding loss function, this one is bidirectional and incorporates the additional negatives when pair-ing queries with passages: \n",
      "\n",
      "LNCE + (B) := \n",
      "\n",
      "Er∼B\n",
      "\n",
      "\"\n",
      "\n",
      "− ln es(q,p )/τ kP\n",
      "\n",
      "> i=1\n",
      "\n",
      "h\n",
      "\n",
      "es(q,p i)/τ + 15 P\n",
      "\n",
      "> j=1\n",
      "\n",
      "es(q,n j,i )/τ \n",
      "\n",
      "i#\n",
      "\n",
      "+ Er∼B\n",
      "\n",
      "\"\n",
      "\n",
      "− ln es(p,q )/τ kP\n",
      "\n",
      "> i=1\n",
      "\n",
      "es(p,q i)/τ \n",
      "\n",
      "#\n",
      "\n",
      "with r = ( q, p, n 1, . . . , n 15 ). (5) \n",
      "\n",
      "5.3 Memory Optimizations \n",
      "\n",
      "When training embedding models, having a large batch size is crucial. This is because the InfoNCE loss functions Lpairs and LNCE + compute the loss values based on the entirety of the batch. The batch size determines the number of text values each in-dividual text value is compared against. As a result, the computed loss value might not be as expres-sive with smaller batches. Li et al. [2023] provided an in-depth analysis, highlighting the positive im-pact of larger batch sizes on the performance of the resultant embedding model. To accommodate larger batch sizes, it becomes essential to mini-mize the memory overhead during training. We achieved this by training our models in mixed pre-cision [Micikevicius et al., 2018] and leveraging the deepspeed [Rasley et al., 2020] framework for fur-ther optimization. Activation checkpointing [Chen et al., 2016] was also employed to curtail memory usage. Specifically, we inserted a checkpoint after each BERT layer within our model. \n",
      "\n",
      "## 6 Evaluation \n",
      "\n",
      "To evaluate the efficacy of our approach, we initiate with a comprehensive analysis of our pre-trained backbone models, as outlined in Section 6.1. This is followed by an in-depth assessment of our em-bedding models in Section 6.2. Furthermore, we have conducted experiments to delve into the ef-fects of encoding extended sequence lengths on the performance of the embeddings, presented in Section 6.2.2. \n",
      "\n",
      "6.1 Evaluation of Jina BERT \n",
      "\n",
      "Following previous work [Liu et al., 2019b], we evaluate our pretrained models on the GLUE bench-mark [Wang et al., 2018]. General Language Un-derstanding Evaluation (GLUE) is a collection of \n",
      "\n",
      "> Figure 2: Variation of model MLM accuracy w.r.t. the sequence length\n",
      "\n",
      "nine datasets for evaluating natural language un-derstanding systems. Six tasks are framed as ei-ther single-sentence classification or sentence-pair classification tasks. The GLUE organizers provide training, development, and test data splits, as well as a submission server and leaderboard. 5 The test split does not contain labels, and the submission server allows participants to evaluate and compare their systems against the private labels of the test split. For the Jina BERT training described in Sec-tion 4, we fine-tune the pre-trained models on the corresponding single-task training data using sev-eral hyperparameter settings and, for each task, pick the best fine-tuning hyperparameters on the development set. Following the methodology of [Phang et al., 2018], for RTE, STS, and MRPC, we fine-tune starting from the MNLI single-task model, rather than the baseline pretrained Jina BERT models. As in the BERT paper [Devlin et al., 2019], our fine-tuning procedure relies on representing the input sequence and using the final hidden vector C ∈ RH\n",
      "\n",
      "corresponding to the first input token ( [CLS] ) as the aggregate representation. We train for 10 epochs with batch sizes {16 , 32 }\n",
      "\n",
      "and learning rates {1e −5, 2e −5, 3e −5}. For each task, the best fine-tuned model on the development set is used for the test set. In Table 2, we report the results of the best-performing models on the test sets after submission to the GLUE benchmark server. Furthermore, we evaluate Jina BERT models on documents of long text sequences by computing                                                                                   \n",
      "\n",
      "> 5https://gluebenchmark.com Model Params MNLI QQP QNLI SST-2 CoLa STS-B MRPC RTE WNLI Average BERT Base 110M 84.6/83.4 71.2 90.5 93.5 52.1 85.8 88.9 66.4 --BERT Large 340M 86.7/85.9 72.1 92.7 94.9 60.5 86.5 89.3 70.1 --RoBERTa 355M 90.8/90.2 90.2 98.9 96.7 67.8 92.2 92.3 88.2 89.0 88.5\n",
      "> Jina BERT Small 33M 80.1/78.9 78.9 86.0 89.6 28.8 84.8 84.1 68.8 55.5 72.9\n",
      "> Jina BERT Base 137M 85.7/85.4 80.7 92.2 94.5 51.4 89.5 88.4 78.7 65.1 80.7\n",
      "> Jina BERT Large 435M 86.6/85.9 80.9 92.5 95.0 59.6 88.2 88.5 78.5 65.1 81.6\n",
      "> Table 2: Evaluation of the Jina BERT models on the GLUE benchmark\n",
      "\n",
      "the accuracy of the MLM task with varying se-quence lengths. The accuracy of masked language modeling is computed on 50 , 000 samples from the C4 validation set where, for each chosen se-quence length, each sample document is tokenized and truncated to fit the sequence length. We com-pare Jina BERT to RoBERTa and BERT models in Figure 2. It essentially shows that, even though \n",
      "\n",
      "Jina BERT models were trained on a 512 sequence length, the MLM accuracy does not drop when we extrapolate to an 8192 sequence length. For other BERT and RoBERTa models, since they use ab-solute positional embeddings that are trained on a \n",
      "\n",
      "512 sequence length, it’s not possible to compute the MLM accuracy beyond 512 . The figure demon-strates ALiBi’s effectiveness in maintaining MLM performance during inference for long documents. \n",
      "\n",
      "6.2 Evaluation of Jina Embeddings v2 \n",
      "\n",
      "To comprehensively evaluate our embedding mod-els, we employ the Massive Text Embedding Benchmark (MTEB) [Muennighoff et al., 2023]. Our choice of MTEB is motivated by its unpar-alleled breadth, distinguishing it among embed-ding benchmarks. Rather than focusing on a single task and dataset, MTEB covers an expan-sive set of 8 tasks, encompassing a rich collec-tion of 58 datasets across 112 languages. This expansive benchmark allows us to scrutinize our model’s adaptability across diverse applications and languages and benchmark it against other top-performing models. However, a limitation of the MTEB benchmark is its omission of very long texts, which are essen-tial for evaluating our model’s prowess in handling \n",
      "\n",
      "8192 sequence lengths. Consequently, we intro-duce new retrieval and clustering tasks featuring ex-tended documents, and we detail the performance of our model against its peers in Section 6.2.2. \n",
      "\n",
      "Clustering : The goal here is to aptly group a collection of sentences or paragraphs. Within the MTEB benchmark suite, a mini-batch k-means model is employed, operating with a batch size of 32. Here, k represents the number of unique la-bels in the dataset. Model performance is evaluated using the V measure, a metric insensitive to cluster label permutations, guaranteeing that assessments are independent of label configurations. We incorporate two new clustering tasks featur-ing extended documents within the MTEB clus-tering task subset. The inaugural task, named PatentClustering, draws from the BigPatent 6\n",
      "\n",
      "dataset [Sharma et al., 2019], challenging the k-means model to organize patents by their respec-tive categories. Patent documents average 6, 376 \n",
      "\n",
      "tokens, spanning a range from a brief 569 tokens to an extensive 218 , 434 tokens. Our second task, ti-tled WikiCitiesClustering, sources from the English subset of the refined Wikipedia dump [Foundation, 2022], available as a dataset on Hugging Face 7. For this task, we curate a roster of nations from Wiki-data and extract Wikipedia articles of their cities from the refined dataset. The objective is to group cities by their parent country. On average, articles consist of 2, 031 tokens, with the length varying between a succinct 21 tokens to a comprehensive \n",
      "\n",
      "20 , 179 tokens. \n",
      "\n",
      "Retrieval : This task entails a dataset comprising a corpus, a set of queries, and associated mappings connecting each query to pertinent corpus docu-ments. The mission is to discern relevant docu-ments for a specific query. Both queries and cor-pus documents undergo encoding, after which their similarity scores are derived using cosine similar-ity. Subsequently, metrics like nDCG @10 (which serves as the primary metric), MRR @k, MAP @k,precision @k, and recall @k are computed for di-verse k values. This task is inspired by datasets and evaluation methods presented by BEIR [Thakur et al., 2021]. To expand the scope of the MTEB, we intro-duce a new retrieval task named NarrativeQA, de-\n",
      "\n",
      "> 6https://huggingface.co/datasets/big_patent\n",
      "> 7https://huggingface.co/datasets/wikipedia\n",
      "\n",
      "rived from the narrativeqa 8 dataset. This dataset boasts realistic QA instances, curated from liter-ature (encompassing both fiction and non-fiction) and film scripts. The corpus averages 74 , 843 to-kens per document, with the lengthiest document tallying up to 454 , 746 tokens, and the most concise one comprising 4, 550 tokens. We further evaluated Jina Embeddings v2 us-ing a novel benchmark, referred to as LoCo 9. The LoCo dataset consists of five retrieval tasks derived from publicly available datasets. The selection pro-cess for these tasks was guided by several criteria, notably the length of the documents, with a prefer-ence towards longer texts, in addition to a manual review to verify that the tasks require a thorough understanding of the entire document. The results of our models on the LoCo dataset are provided in Table 11. \n",
      "\n",
      "6.2.1 Results on MTEB \n",
      "\n",
      "The evaluation of embedding models within the MTEB benchmark, as illustrated in Table 3, re-veals significant contrasts between Jina’s text embedding models, namely jina-small-v2 and \n",
      "\n",
      "jina-base-v2 , and other contemporary models. These differences are especially pronounced in tasks showing marked performance disparities, such as Classification (CF) and Retrieval (RT). In Classification (CF), the jina-base-v2 model, equipped with 137 million parameters, emerges as a leading performer. It records superior scores, outpacing most competing models, underscoring its efficacy in text classification. Conversely, the \n",
      "\n",
      "jina-small-v2 model, equipped with a modest 33 million parameters, trails behind some other models in this task. This underscores the pivotal role model size plays in certain downstream tasks, with more extensive architectures yielding potential benefits. For the Retrieval (RT) task, jina-small-v2 \n",
      "\n",
      "showcases formidable performance, signaling its adeptness for information retrieval. It ranks amidst top-tier models, indicating its prowess in retrieval-centric tasks. Similarly, \n",
      "\n",
      "jina-base-v2 excels, registering a slightly su-perior score, reaffirming its formidable retrieval aptitude. Both models underscore their credibil-ity in tasks necessitating adept information re-trieval. Given that models all-MiniLM-L6-v2 and \n",
      "\n",
      "> 8https://huggingface.co/datasets/narrativeqa\n",
      "> 9https://hazyresearch.stanford.edu/blog/ 2024-01-11-m2-bert-retrieval\n",
      "\n",
      "all-mpnet-base-v2 omit the second-stage fine-tuning which jina-small-v2 and jina-base-v2 \n",
      "\n",
      "undergo, it’s foreseeable that our models would excel in these tasks. In conclusion, both the base and small text embedding models display commendable perfor-mance within the MTEB benchmark. Their stand-out performance, relative to other models in tasks like Classification and Retrieval, suggests model size’s influential role in specific text processing en-deavors. Both models reaffirm their potency in re-trieval, marking them as pivotal tools for a plethora of natural language processing tasks. \n",
      "\n",
      "6.2.2 Impact of Maximum Sequence Length \n",
      "\n",
      "As delineated in Section 6.1, the pre-training gen-eralizes across extended sequence lengths. Con-sequently, the MLM accuracy for long sequences, spanning up to 8192 tokens, mirrors that of shorter sequences, despite the exclusive training on ab-breviated text sequences. During finetuning, our models train solely on texts not exceeding 512 to-kens, yet they cater to texts reaching 8192 tokens for the MTEB evaluation detailed in Section 6.2. To discern how sequence length impacts the ac-curacy of downstream tasks, we executed long doc-ument clustering and retrieval tasks, modulating the tokenizer’s maximum sequence length. This allows us to gauge the models’ performance on vari-able sequence lengths through truncation. Since a majority of the extant tasks in the MTEB feature documents under 512 tokens, we resort to our three novel datasets elucidated in Section 6.2, accessi-ble on Hugging Face. Furthermore, we employ the SciFact dataset [Wadden et al., 2020], given its substantial count of texts exceeding 512 tokens. Figure 3 depicts the nDCG @10 retrieval and the V measure scores for the jina-base-v2 \n",
      "\n",
      "alongside four other renowned embedding mod-els. Given that only jina-base-v2 and Ope-nAI’s text-embedding-ada-002 support an 8K sequence length, results reported for an 8191 se-quence length for other models are truncated to their intrinsic maximum, typically 512 . Generally, Figure 3 suggests that elongated sequence lengths contribute to enhanced outcomes. This assertion is particularly true for the NarrativeQA task, where extending the sequence length substantially bol-sters performance. Due to the inherent nature of the dataset, models limited to the text’s commence-ment frequently underperform. On the BigPatent clustering task, larger sequence Model Params CF CL PC RR RT STS SM Average                                                             \n",
      "\n",
      "> text-embedding-ada-002 unknown 70.93 45.90 84.89 56.32 49.25 80.97 30.80 60.99 e5-base-v2 110M 73.84 43.80 85.73 55.91 50.29 81.05 30.28 61.50 all-MiniLM-L6-v2 23M 63.05 42.35 82.37 58.04 41.95 78.90 30.81 56.26 all-mpnet-base-v2 110M 65.07 43.69 83.04 59.36 43.81 80.28 27.49 57.78\n",
      "> jina-small-v2 33M 68.82 40.08 84.44 55.09 45.64 80.00 30.56 58.12\n",
      "> jina-base-v2 137M 73.45 41.74 85.38 56.99 48.45 80.70 31.60 60.37 CF: Classification Accuracy [%] CL: Clustering Vmeasure[%] PC: Pair Classification Average Precision [%] RR: Reranking MAP [%] RT: Retrieval nDCG@10 STS: Sentence Similarity Spearman Correlation [%] SM: Summarization Spearman Correlation [%]\n",
      "\n",
      "Table 3: Evaluation of the Jina Embeddings v2 models on the MTEB benchmark \n",
      "\n",
      "Figure 3: Evaluation w.r.t. maximum sequence length. For e5-base-v2 , we abstained from employing specific prefixes like query: , which might result in varied evaluation outcomes. Note, text-embedding-ada-002 caps its context length at 8191 tokens, not 8192 .\n",
      "\n",
      "lengths also result in better performance. However, on the WikiCities clustering task, longer sequence lengths seem to slightly diminish the models’ per-formance in most instances. This suggests that an increase in sequence length doesn’t always yield better outcomes. One explanation for this obser-vation is that the initial paragraph of a Wikipedia article about a city typically mentions the country the city is in. Information towards the middle and end of the articles is often less pertinent for identi-fying the country and might alter the attributes that influence the clustering of the city embeddings. \n",
      "\n",
      "## 7 Conclusion \n",
      "\n",
      "We have introduced Jina Embeddings v2 , a novel embedding model based on a modified BERT archi-tecture. This model eschews positional embeddings and instead employs bi-directional ALiBi slopes to capture positional information. By training a series of embedding models with this innovative architecture on the Web document corpus C4 and subsequently fine-tuning them, we have enabled the encoding of the semantics of both short and long textual values into meaningful vector repre-sentations. This effort has produced a new suite of open-source embedding models capable of en-coding texts containing up to 8192 tokens. These embeddings signify a 16x increase in the maximum sequence length compared to leading open-source embedding models. Additionally, our model suite exhibits competitive performance on the MTEB benchmark. We also demonstrate how utilizing ex-tended sequence lengths can offer our models an advantage over those without such capabilities. \n",
      "\n",
      "## References \n",
      "\n",
      "Nils Reimers and Iryna Gurevych. Sentence-bert: Sen-tence embeddings using siamese bert-networks. In \n",
      "\n",
      "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-guage Processing (EMNLP-IJCNLP) , pages 3982– 3992, 2019. Ofir Press, Noah A. Smith, and Mike Lewis. Train short, test long: Attention with linear biases enables input length extrapolation, 2022. Michael Günther, Louis Milliken, Jonathan Geuter, Georgios Mastrapas, Bo Wang, and Han Xiao. Jina embeddings: A novel set of high-performance sentence embedding models. arXiv preprint arXiv:2307.11224 , 2023. Liang Wang, Nan Yang, Xiaolong Huang, Binx-ing Jiao, Linjun Yang, Daxin Jiang, Rangan Ma-jumder, and Furu Wei. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533 , 2022. Scott Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard Harshman. Index-ing by latent semantic analysis. Journal of the Amer-ican Society for Information Science , 41(6):391–407, 1990. David Blei, Andrew Ng, and Michael Jordan. Latent dirichlet allocation. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neu-ral Information Processing Systems , volume 14. MIT Press, 2001. URL https://proceedings. neurips.cc/paper_files/paper/2001/file/ 296472c9542ad4d4788d543508116cbc-Paper. pdf .Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of sentence embeddings, 2022. Luyu Gao and Jamie Callan. Condenser: a pre-training architecture for dense retrieval, 2021. Shitao Xiao, Zheng Liu, Yingxia Shao, and Zhao Cao. Retromae: Pre-training retrieval-oriented language models via masked auto-encoder, 2022. Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang. Towards general text embeddings with multi-stage contrastive learn-ing, 2023. Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab-hishek Srivastava, and Iryna Gurevych. Beir: Aheterogenous benchmark for zero-shot evaluation of information retrieval models, 2021. Niklas Muennighoff, Nouamane Tazi, Loïc Magne, and Nils Reimers. Mteb: Massive text embedding bench-mark, 2023. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidi-rectional transformers for language understanding, 2019. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019a. Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated convolu-tional networks. CoRR , abs/1612.08083, 2016. URL \n",
      "\n",
      "http://arxiv.org/abs/1612.08083 .Noam Shazeer. GLU variants improve transformer. \n",
      "\n",
      "CoRR , abs/2002.05202, 2020. URL https://arxiv. org/abs/2002.05202 .Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR , abs/1706.03762, 2017. URL http: //arxiv.org/abs/1706.03762 .Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan-zaro. Megatron-lm: Training multi-billion parameter language models using model parallelism. CoRR ,abs/1909.08053, 2019. URL http://arxiv.org/ abs/1909.08053 .Toan Q. Nguyen and Julian Salazar. Transformers without tears: Improving the normalization of self-attention. CoRR , abs/1910.05895, 2019. URL \n",
      "\n",
      "http://arxiv.org/abs/1910.05895 .Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of trans-fer learning with a unified text-to-text transformer. \n",
      "\n",
      "The Journal of Machine Learning Research , 21(1): 5485–5551, 2020. Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. CoRR , abs/1711.05101, 2017. URL http://arxiv.org/abs/1711.05101 .Paulius Micikevicius, Sharan Narang, Jonah Alben, Gre-gory Diamos, Erich Elsen, David Garcia, Boris Gins-burg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, et al. Mixed precision training. In Inter-national Conference on Learning Representations ,2018. Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , pages 3505–3506, 2020. Zhuyun Dai, Vincent Y Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith Hall, and Ming-Wei Chang. Promptagator: Few-shot dense retrieval from 8 examples. In The Eleventh In-ternational Conference on Learning Representations ,2023. URL https://openreview.net/forum?id= gmL46YMpu2J .Aäron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. CoRR , abs/1807.03748, 2018. URL http: //arxiv.org/abs/1807.03748 .Feng Wang and Huaping Liu. Understanding the be-haviour of contrastive loss. In 2021 IEEE/CVF Con-ference on Computer Vision and Pattern Recognition (CVPR) , pages 2495–2504. IEEE, 2021. Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268 , 2016. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-field, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural ques-tions: a benchmark for question answering research. \n",
      "\n",
      "Transactions of the Association of Computational Linguistics , 2019. Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In Proceed-ings of the 2015 Conference on Empirical Methods in Natural Language Processing , pages 632–642, 2015. Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear mem-ory cost. arXiv preprint arXiv:1604.06174 , 2016. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. \n",
      "\n",
      "CoRR , abs/1907.11692, 2019b. URL http://arxiv. org/abs/1907.11692 .Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. GLUE: A multi-task benchmark and analysis platform for natu-ral language understanding. CoRR , abs/1804.07461, 2018. URL http://arxiv.org/abs/1804.07461 .Jason Phang, Thibault Févry, and Samuel R. Bow-man. Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks. CoRR ,abs/1811.01088, 2018. URL http://arxiv.org/ abs/1811.01088 .Eva Sharma, Chen Li, and Lu Wang. BIGPATENT: A large-scale dataset for abstractive and coherent summarization. CoRR , abs/1906.03741, 2019. URL \n",
      "\n",
      "http://arxiv.org/abs/1906.03741 .Wikimedia Foundation. Wikimedia downloads, 2022. URL https://dumps.wikimedia.org .David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. Fact or fiction: Verifying scien-tific claims. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process-ing (EMNLP) , pages 7534–7550, 2020. A Appendix: MTEB and LoCo Becnharmk \n",
      "\n",
      "Accuracy [%] Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "AmazonCounterfactualClassification 71.36 74.73 AmazonPolarityClassification 82.90 88.54 AmazonReviewsClassification 40.89 45.26 Banking77Classification 78.25 84.01 EmotionClassification 44.01 48.77 ImdbClassification 73.64 79.44 MassiveIntentClassification 67.61 71.93 MassiveScenarioClassification 69.75 74.49 MTOPDomainClassification 93.96 95.68 MTOPIntentClassification 72.50 83.15 ToxicConversationsClassification 71.54 73.35 TweetSentimentExtractionClassification 59.40 62.06 Avg 68.82 73.45 \n",
      "\n",
      "> Table 4: Detailed Performance on the MTEB Classification Tasks\n",
      "\n",
      "V measure Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "ArxivClusteringP2P 44.02 45.39 ArxivClusteringS2S 35.16 36.68 BiorxivClusteringP2P 35.57 37.05 BiorxivClusteringS2S 29.07 30.16 MedrxivClusteringP2P 31.86 32.41 MedrxivClusteringS2S 27.51 28.09 RedditClustering 49.28 53.05 RedditClusteringP2P 57.09 60.31 StackExchangeClustering 55.35 58.52 StackExchangeClusteringP2P 34.42 34.96 TwentyNewsgroupsClustering 41.57 42.47 Avg 40.08 41.73 \n",
      "\n",
      "> Table 5: Detailed Performance on the MTEB Clustering Tasks\n",
      "\n",
      "Spearman correlation based on cos similarity Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "SummEval 30.56 31.60 \n",
      "\n",
      "> Table 6: Detailed Performance on the MTEB Summarization Tasks\n",
      "\n",
      "cos -sim-ap \n",
      "\n",
      "Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "SprintDuplicateQuestions 95.12 95.30 TwitterSemEval2015 72.15 74.74 TwitterURLCorpus 86.05 86.09 Avg 84.44 85.38 \n",
      "\n",
      "> Table 7: Detailed Performance on the MTEB Pair Classification Tasks\n",
      "\n",
      "mAP@10 Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "AskUbuntuDupQuestions 59.62 62.25 MindSmallReranking 30.99 30.54 SciDocsRR 79.76 83.10 StackOverflowDupQuestions 49.99 52.05 Avg 55.09 56.98 \n",
      "\n",
      "> Table 8: Detailed Performance on the MTEB ReRanking Tasks\n",
      "\n",
      "nDCG@10 Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "ArguAna 46.73 44.18 ClimateFEVER 20.05 23.53 CQADupstackRetrieval 38.03 39.34 DBPedia 32.65 35.05 FEVER 68.02 72.33 FiQA2018 33.43 41.58 HotpotQA 56.48 61.38 MSMARCO 37.28 40.92 NFCorpus 30.40 32.45 NQ 51.59 60.44 QuoraRetrieval 87.19 88.20 SCIDOCS 18.61 19.86 SciFact 63.89 66.68 Touche2020 23.52 26.24 TRECCOVID 65.18 65.91 Avg 45.14 47.87 \n",
      "\n",
      "> Table 9: Detailed Performance on the MTEB Retrieval Tasks\n",
      "\n",
      "Spearman correlation based on cosine similarity Task jina-small-v2 jina-base-v2 \n",
      "\n",
      "BIOSSES 80.52 81.23 SICK-R 76.72 79.65 STS12 73.66 74.27 STS13 83.30 84.18 STS14 79.17 78.81 STS15 87.30 87.55 STS16 83.61 85.35 STS17(en-en) 88.23 88.88 STS22(en) 63.46 62.20 STSBenchmark 84.04 84.84 Avg 80.00 80.70 \n",
      "\n",
      "> Table 10: Detailed Performance on the MTEB STS Tasks\n",
      "\n",
      "Model Fine-tuned on LoCo Parameters Context Length avg. nDCG@10 M2-BERT-32768 ✓ 80M 32,768 92.5 e5-mistral-7b-instruct 7.3B 4,096 88.5 M2-BERT-32768 ✓ 80M 8,192 85.9 \n",
      "\n",
      "jina-base-v2 137M 8192 85.4 bge-large-en-v1.5 ✓ 335M 512 85.0 M2-BERT-2048 ✓ 80M 2,048 83.6 \n",
      "\n",
      "jina-small-v2 33M 8,192 83.4 bge-base-en-v1.5 ✓ 109M 512 83.0 bge-small-en-v1.5 ✓ 33M 512 81.2 bge-large-en-v1.5 335M 512 77.2 bge-base-en-v1.5 109M 512 73.4 bge-small-en-v1.5 33M 512 70.6 cohere-embed-v3 NA 512 66.6 ada-embeddings-002 NA 8,191 52.7 voyage-v1 NA 4,096 25.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdfjdata = jinaai_readerapi_web_scrape_url(pdf_url)\n",
    "print(pdfjdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morgage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
